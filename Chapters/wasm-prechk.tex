\chapter{\name}
\label{chp:prechk}
The goal of \name is to be used to eliminate unnecessary dynamic checks.
To accomplish this, it must be able to (1) facilitate removing dynamic checks on instructions and (2) statically prove that certain instructions do not require dynamic checks.
In \name, we extend \wasm with new instructions that explicitly do not require dynamic checks, and design an indexed type system to reason about the safety of removing checks.

\section{\name Syntax}
The syntax of \name is highly similar to that of \wasm except for two additions.
First, \name introduces four additional instructions, which are referred to as ``\prechk-tagged'' instructions.
Second, \name changes the representation of types within \wasm instructions and functions.

\subsection{\prechk-tagged Instructions}
There are four \wasm instructions that require run-time checks (see \ref{subsec:wasmsemantics}).
``\prechk-tagged'' instructions refer to a set of four \name instructions, listed in \ref{fig:newinstructions}, that are counterparts to these four \wasm instructions.
Intuitively, we are simply adding a tag to the instruction to show that it doesn't require run-time checks.
Formally, however, these are different instructions with different semantics and different typing rules, as explained below.

\begin{figure}[t]
    \begin{align*}
        &t.\<divpc> \mid
        t.\<callindirectpc> \mid
        \\
        &t.\<loadpc> (tp\_sx)^{?}\; a\;o \mid
        t.\<storepc> tp^{?\;} a\;o
    \end{align*}
    \caption{The four \prechk-tagged instructions}
    \label{fig:newinstructions}
\end{figure}

\subsection{The \name Index Language}
\label{subsec:indexlang}
\name uses an indexed type system.
An indexed type language uses an index language in the type system to encode information within types.
We use the index language to encode linear constraints on program variables within types.
Figure~\ref{fig:itsyntax} shows the syntax for the index type language.
Syntax written in a \tbbf{blue, bold font} denotes a \wasm keyword.
Below is a quick overview of each of the terms.

\begin{figure}[t]
    \begin{math}
        \begin{array}{rcl}
            t &:: & \<ithreetwo> \mid \<isixfour> \\
            a &::= & Var \\
            x\;y &::=& a \mid \ti{t}{c} \mid (\<binop>\;x\;y) \mid (\<testop>\;x) \mid (\<relop>\;x\;y) \\
            P &::=& (=\; x \; y) \mid (if\; P\; P\; P) \mid \neg P \mid P \land P \mid P \lor P \\
            \phi &::=& \circ \mid \phi, \ti{t}{a} \mid \phi, P \\
        \end{array}
    \end{math}
    \caption{Syntax of the \name index type language}
    \label{fig:itsyntax}
\end{figure}

\begin{itemize}
    \item $t$ represents a primitive \wasm type.
    We do not reason about floating points, so it is either a 32-bit integer ($i32$) or a 64-bit integer ($i64$).
    \item $a$ is a type index variable, which is used to track constraints on program variables.
    \item $x$ and $y$ are type indices, they can be an index type variable, a constant with an explicit type, or a \wasm operation on a type index.
    \item $P$ is a proposition about type indices which can encode equality constraints on type indices, or combine propositions using common first-order logic operators.
    \item $\phi$ is the type index context which stores index type variable declarations and propositions.
\end{itemize}

In \name, we extend \wasm's technique for handling the stack to include an index context $\phi$ (which contains type index variable declarations and the constraints on indices) and the index types of local and global variables (similar to the Register file in \dtal) in the precondition and postcondition.

The index local store associates index variables with \wasm local variables.
It has an identical form to the stack (a list of indexed types to associate index variables with local variables).
We use the shorthand $l$ to refer to the index local store since we rarely reason about it but rather thread it through typing rules.
The index type context $\phi$ is the mechanism that is used to reason about the possible values of computations
It stores constraints on and between program variables tracked by indexed types representing the stack and index local store.

In the \name type system, the shape of the stack is represented by indexed types, $ti ::= \ti{t}{a}$, which include both the expected \wasm type $t$, and the index variable $a$ that is associated with the value on the stack.
Further, the precondition and postcondition of function types are extended to include the index local store $l$ and the index type context $\phi$.
We refer to these extended function types as indexed function types: $tfi ::= ti_1^{*};l_1;\phi_1 \rightarrow ti_2^{*};l_2;\phi_2$.
Certain \wasm instructions (such as $\<block>$, $\<loop>$, and $\<if>$), include \wasm function types to declare the expected types of their bodies.
In \name, we replace those function types with indexed function types.

We retain $C$ to refer to the module type context in \name, except that we replace \wasm function types with \name indexed function types, and replace the postcondition types in the label stack and return stack with \name indexed postcondition types.

\section{\name Semantics}
The formal reason certain \wasm instructions require run-time checks is because they have preconditions as part of their semantics, and if the preconditions are not met then those instructions trap to avoid undefined behavior.
The \wasm type system is not expressive enough to ensure these preconditions statically, so they instead must be checked at run-time.
Conversely, ``\prechk-tagged'' instructions can assume that the preconditions on their behavior hold because it is enforced by the \name type system.
This can be seen in the reduction rules for the ``\prechk-tagged'' instructions in Figure \ref{fig:prechkredux}, where they do not have rules to trap when their preconditions do not hold.

\label{sec:newinstructions}
\begin{figure}[t]
    \todo{This display sucks cause it just can't fit on the page :(}
    \begin{math}
        \arraycolsep=1.4pt
        \begin{array}{rcl}
            (t.\<const> c_1)\;(t.\<const> c_2) && \\
            t.\<divpc> & \hookrightarrow & c \\
            && \text{if } c_2 \neq 0 \land c=c_1/c_2 \\
            s;(t.\<const> j) && \\
            t.\<callindirectpc> & \hookrightarrow_i & \<call> s_{tab}(i,j) \\
            &&\text{if } s_{tab}(i,j) = \\
            && \<func> tfi\; \<local>\; t^{*}\;e^{*} \\
            s;(\<ithreetwo>.\<const> k) && \\
            (t.\<loadpc> (tp\_sx)^{?}\; a\;o) & \hookrightarrow_i & t.\<const> const_t(b^{*}) \\
            && \text{if } s_{mem}(i,k+o,|t|)=b^{*} \\
            s;(\<ithreetwo>.\<const> k)\;(t.\<const> c) && \\
            (t.\<storepc> tp^{?}\; a\;o) & \hookrightarrow_i & s';\epsilon \\
            && \text{if } s'=s \\
            && \text{with mem}(i,k+o,|t|)=bits_t^{|t|}(c) \\
        \end{array}
    \end{math}
    \caption{Behavior of new \prechk-tagged instructions}
    \label{fig:prechkredux}
\end{figure}

All other \name instructions have equivalent semantics to their \wasm versions.

\section{The \name Indexed Type System}
\label{sec:typesys}
The \name type system is designed to provide sufficient information to safely eliminate dynamic checks (\ie to ensure that the required preconditions are met to \prechk-tag an instruction).
As explained in ~\ref{subsec:indexlang}, the \name type system can encode linear constraints on program variables in the preconditions and postconditions of instructions.
We will now show how these constraints are added and used.

The main typing judgement in \name, like in \wasm, is for lists of instructions.
It has the form $C \vdash e^{*} : tfi$, where $C$ is the indexed module type context, $e^{*}$ is a sequence of instructions, and $tfi$ is the precondition and postcondition of the instruction (wrapped into a function type).
Generally, there are two types of rules.
Most rules are for inferring or checking the types of instructions (in which case $e^{*}$ will be a single instruction).
There are also a few rules to compose together instruction sequences.
We present the typing rules mixed with discussion of those rules.
The typing judgment in its entirety is reproduced in the appendix.

A number of typing rules are essentially equivalent to their \wasm counterparts.
These are rules don't use or modify index type information.
$\<unreachable>$ accepts any precondition and guarantees any postcondition.
$\<nop>$ has the same precondition and postcondition.
$\<drop>$ consumes the top value from the stack and does not change the local index store or index type context.
\begin{mathpar}
    \inferrule[]{ }{ %% unreachable
        C \vdash \<unreachable> : tfi
    }

    \inferrule[]{ }{ %% nop
        C \vdash \<nop> : \epsilon;l;\phi \rightarrow \epsilon;l;\phi
    }

    \inferrule[]{ }{ %% drop
        C \vdash \<drop> : \ti{t}{a};l;\phi \rightarrow \epsilon;l;\phi
    }
\end{mathpar}

The constant instruction is probably the simplest example of how indexed types work.
It adds a new indexed type onto the stack to track the new program variable $\ti{t}{a}$ (where $a$ is fresh), declares the new indexed type in the index type context, and constrains that indexed type to be equal to the constant $(= a\; \ti{t}{c})$.
The local index store is unchanged between the precondition and postcondition.
\begin{mathpar}
    \inferrule[]{ }{ %% const
        C \vdash t.\<const> c : \epsilon;l;\phi \rightarrow \ti{t}{a};l;\phi,\ti{t}{a},(= a \ti{t}{c})
    }
\end{mathpar}

There are several different types of operations, but they all work similarly.
The binary operator instruction adds constraints between new and old program variables, since the result of the instruction is a new program variable, while the consumed values may already be constrained.
A binary operation consumes two indexed types from the stack, $\ti{t}{a_1}$ and $\ti{t}{a_2}$, and produces a fresh indexed type, $\ti{t}{a_3}$.
The index type declaration $\ti{t}{a_3}$ is added to the index type context $\phi$ and $a_3$ is constrained to be equal to the binary operator applied to the index variables that correspond to the input $(= a_3\;(binop\;a_1\;a_2)$.
Binary operators do not affect or use local variables, they simply propagate, so the local index store is the same in the precondition and postcondition.
\begin{mathpar}
    \inferrule[]{ }{ %% binop
        C \vdash t.relop : \ti{t}{a_1}\;\ti{t}{a_2};l;\phi \rightarrow \ti{t}{a_3};l;\phi,\ti{t}{a_3},(= a_3\;(relop\;a_1\;a_2))
    }

    \inferrule[]{ }{ %% testop
        C \vdash t.testop : \ti{t}{a_1}\;l;\phi \rightarrow \ti{t}{a_2};l;\phi,\ti{t}{a_2},(= a_2\;(testop\;a_1))
    }

    \inferrule[]{ }{ %% relop
        C \vdash t.relop : \ti{t}{a_1}\;\ti{t}{a_2};l;\phi \rightarrow \ti{t}{a_3};l;\phi,\ti{t}{a_3},(= a_3\;(relop\;a_1\;a_2))
    }
\end{mathpar}

The select rule constrains indexed types in a rather complex way.
Select consumes three values from the stack, it returns the second value if the third value is zero, and otherwise returns the first value (similar to C's ternary operator).
For this rule we use the dependent ``if'' to allow the constraint on the result to depend on the third value consumed: $(if\; (= a\; \ti{\<ithreetwo>}{0})\; (= a_3\;a_2)\; (= a_3\;a_1))$.
\begin{mathpar}
    \inferrule[]{ }{ %% select
        C \vdash \<select> : {\begin{stackTL}
            \ti{t}{a_1}\;\ti{t}{a_2}\;\ti{i32}{a};l;\phi
            \\ \rightarrow \ti{t}{a_3};l;\phi,\ti{t}{a_3},
                (if\; (= a\; \ti{\<ithreetwo>}{0})\; (= a_3\;a_2)\; (= a_3\;a_1))
        \end{stackTL}}
    }
\end{mathpar}

The rules for the three different types of blocks (blocks, if blocks, and loops) are similar to \wasm.
They simply ensure that the interior instruction sequence has the expected type under the context with the expected postcondition (or precondition in the case of loop) appended to the local stack.
If blocks are able to make extra assumptions about the consumed value in the subsequences (that it is non-zero in the first sequence and zero in the second), because those constraints must be true for that sequence to be executed..

One thing to note is that all three of these rules include their expected indexed function types as part of their syntax.
We consider the index variables in these indexed function types to be patterns rather then literals, allowing them to match any literal as long as the same pattern matches the same literal (\ie $a_1$ matches $foo$ in both the local index store and index type context).
Intuitively, this is very similar to alpha equivalence, where the precondition matches any preceding postcondition with the same structure as long as the variable can be renamed to match.
The postcondition appended to the label stack also has pattern variables instead of the supplied literals.
\begin{mathpar}
    \inferrule[]{ %% block
        tfi = ti_1^{*};l_1;\phi_1 \rightarrow ti_2^{*};l_2;\phi_2 \\
        C_2,\text{label } (ti_2^{*};l_2;\phi_2) \vdash e^{*} : tfi \\
    }
    {
        C \vdash \<block> tfi\; e^{*} \<end> : tfi
    }

    \inferrule[]{ %% loop
        tfi = ti_1^{*};l_1;\phi_1 \rightarrow ti_2^{*};l_2;\phi_2 \\
        C_2,\text{label } (ti_1^{*};l_1;(\phi_1)^{*}) \vdash e^{*} : tfi \\
    }
    {
        C \vdash \<loop> tfi\; e^{*} \<end> : tfi
    }

    \inferrule[]{ %% if
        tfi = ti_1^{*};l_1;\phi_1 \rightarrow ti_2^{*};l_2;\phi_2 \\
        C_2,\text{label } (ti_2^{*};l_2;\phi_2) \vdash e_1^{*} : ti_1^{*};l_1;\phi_1, \neg(= a\; \ti{\<ithreetwo>}{0}) \rightarrow ti_2^{*};l_2;\phi_2 \\
        C_2,\text{label } (ti_2^{*};l_2;\phi_2) \vdash e_2^{*} : ti_1^{*};l_1;\phi_1, (= a\; \ti{\<ithreetwo>}{0})) \rightarrow ti_2^{*};l_2;\phi_2 \\
    }
    {
        C \vdash \<if> tfi\; e_1^{*} \<else> e_2^{*} \<end> : tfi
    }
\end{mathpar}

The rules for branching instructions and return are for the most part similar to \wasm.
However, $br_if$ adds the assumption that the consumed value is zero to its postcondition.
This assumption can be safely added because the value must be zero for execution to continue without a branch occurring.
If the consumed value is constrained to be non-zero in the indexed type system, then this will cause a contradiction in the constraints of the index type context, however, that is fine since this means that no instructions following the $br_if$ will be executed.
Also remember the above note that the postconditions on the label stack contain pattern index variables.

\begin{mathpar}
    \inferrule[]{ %% br
        C_{\text{label}}(i) = ti^{*};l_1;\phi_1
    }
    {
        C \vdash \<br> i : ti_1^{*}\;ti^{*};l_1;\phi_1 \rightarrow ti_2^{*};l_2;\phi_2
    }

    \inferrule[]{ %% return
        C_{\text{return}} = ti^{*};l_1;\phi_1
    }
    {
        C \vdash \<return> : ti_1^{*}\;ti^{*};l_1;\phi_1 \rightarrow ti_2^{*};l_2;\phi_2
    }

    \inferrule[]{ %% br_if
        C_{\text{label}}(i) = ti^{*};l_1;\phi_1,\neg(= a\; \ti{\<ithreetwo>}{0})
    }
    {
        C \vdash \<brif> i : ti^{*}\;\index{i32}{a};l_1;\phi_1 \rightarrow ti^{*};l_1;\phi_1,(= a\; \ti{\<ithreetwo>}{0})
    }

    \inferrule[]{ %% br_table
        (C_{\text{label}}(i) = ti^{*};l_1;\phi_i)^{+} \and
        (\phi_1 \implies \phi_i)^n
    }
    {
        C \vdash \<brtable> i^{+} : ti_1^{*}\;ti^{*}\;\index{i32}{a};l_1;\phi_1 \rightarrow ti_2^{*};l_2;\phi_2
    }
\end{mathpar}

Function calls have the same type as the expected indexed function type of the function they are calling with two differences.
First, the local index store is unchanged, since the called function operates on separate local variables.
Second, the index type context in the postcondition is extended with the declarations and constraints from the precondition.
The precondition and postcondition of a function can only contain constraints about the arguments supplied to that function, so simply copying the postcondition of the function would result in the lose of information about all other program variables.

For direct function calls, the expected indexed function type is the type associated with the function in the indexed module type context.
Indirect function calls have their expected types provided as part of instructions, where the same note about index variables being patterns from above holds.
\begin{mathpar}
    \inferrule[]{ %% call
        C_{func}(i) = ti_1^{*};l_1;\phi_1 \rightarrow ti_2^{*};l_2;\phi_2
    }
    {
        C \vdash \<call> i : ti_1^{*};l;\phi_1 \rightarrow ti_2^{*};l;\phi_1,\phi_2
    } \and
    \inferrule[]{ %% call_indirect
        C_{table}(i) = (j, tfi_2^{*}) \and
        tfi = ti_1^{*};l_1;\phi_1 \rightarrow ti_2^{*};l_2;\phi_2
    }
    {
        C \vdash \<callindirect> tfi : ti_1^{*}\;\ti{i32}{a};l;\phi_1 \rightarrow ti_2^{*};l;\phi_1,\phi_2
    } \and
\end{mathpar}

The only instructions that actually mutate the local index store are those that operate on local variables.
$\<getlocal>$ produces a fresh indexed type that is constrained to be equal to the index variable associated with the local being retrieved.
$\<setlocal>$ works in the reverse direction, replacing the index variable associated with the local being set with a fresh indexed type constrained to be equal to the value consumed.
Finally, $\<teelocal>$ is effectively a $\<setlocal>$ that consumes and immediately regurgitates the indexed type back onto the stack.
\begin{mathpar}
    \inferrule[]{ %% get_local
        C_{\text{local}}(i) = t \and
        l(i) = \ti{t}{a}
    }
    {
        C \vdash \<getlocal> i : \epsilon;l;\phi \rightarrow \ti{t}{a_2};l;\phi, \ti{t}{a_2}, (= a_2\; a)
    }

    \inferrule[]{ %% set_local
        C_{\text{local}}(i) = t \and
        l_2 = l_1 \text{ except } l_2(i) = \ti{t}{a_2}
    }
    {
        C \vdash \<setlocal> i : \ti{t}{a};l_1;\phi \rightarrow \epsilon;l_2;\phi, \ti{t}{a_2}, (= a_2\; a)
    }

    \inferrule[]{ %% tee_local
        C_{\text{local}}(i) = t \and
        l_2 = l_1 \text{ except } l_2(i) = \ti{t}{a_2}
    }
    {
        C \vdash \<teelocal> i : \ti{t}{a};l_1;\phi \rightarrow \ti{t}{a};l_2;\phi, \ti{t}{a_2}, (= a_2\; a)
    }
\end{mathpar}

\subsection{Using Types for Check Elimination}
\name can currently eliminate checks for four types of instructions: memory loads and stores (similar to \dtal), integer division, and indirect function calls.
Tagging memory loads and stores with \prechk requires ensuring that the memory index is valid.
The integer division instruction can be \prechk tagged if the second argument is provably non-zero.
Indirect function calls are a particularly interesting case that is specific to \wasm: they are used to safely handle function pointers when compiling from C/C++ and require a dynamic check to ensure that the called function has a suitable type.
Proving the safety of an indirect function call involves showing that every possible function that could be called will not cause a run-time type error.

Integer division simply requires that the second argument is non-zero.
For example, the second rule in Figure \todo{figure} ensures that pre-checked division instructions can be safely executed.
The premise $\phi \implies (neq\ b\ 0)$ requires that the index constraints satisfy the proposition $b \neq 0$ for the pre-checked instruction to be safe.
Therefore, since a divide-by-zero is provably absent, it is safe to replace the division operator instruction with the \prechk-tagged version.

\subsection{Subtyping, Implication, and Constraint Satisfaction}
One issue with adding the index type context $\phi$ to preconditions and postconditions is that the postcondition of one instruction and the precondition of the next instruction might not match up exactly.
For example, one instruction may ensure a value is greater than ten, but the next just wants the value to be greater than zero.
Intuitively, if a value, ``x'', is greater than ten it must also be greater than zero, and we want the \name type system to be able to figure this out as well.
However, computers as of yet are unable to use intuition, so we must instead formalize this intuition such that a computer can reason about it.

Our formalization of this problem is based on Hoare logic \todo{find proper citation}.
Hoare logic similarly has preconditions and postconditions on statements, and allows those preconditions to be \emph{strengthened} and postconditions to be \emph{weakened}.
Strengthening and weakening is based on implication ($\implies$).
We say that $\phi_1 \implies \phi_2$ when the following holds: if $\phi_1$ is satisfied, then $\phi_2$ must also be satisfied.
If $\phi_1 \implies \phi_2$, then we consider $\phi_1$ to be stronger than $\phi_2$, and $\phi_2$ to be weaker than $\phi_1$.
This solves the aforementioned problem because we can weaken ``x is greater than 10'' to ``x is greater than 0'' (or equivalently strengthen ``x is greater than 0'' to ``x is greater than 10'').

In practice, we reason about implication using the Z3 theorem prover \todo{citation needed}.
To test whether the satisfiability of one index type context $\phi_1$ implies that some other index type context $\phi_2$ is satisfiable, we first generate Z3 constraints based on the propositions in both contexts.
Then, we assert that the constraints generated for the first context must hold.
Finally, we ask Z3 to find an assignment to the variables declared in the type index contexts where the constraints from the second context do not hold (a counterexample).
If a counterexample cannot be found then the implication must hold, otherwise it does not hold.

\todo{Need to format the digression to set it apart}
\thought{Maybe this is better moved to the discussion section to discuss as part of the implementation?}
\paragraph{Digression about impact of using Z3.}
Our choice of using Z3 has impacted \name in several ways.
\begin{itemize}
    \item The biggest impact is that we currently do not supporting floating point values and certain unary and binary operators because Z3 is unable to reason about them.
    \item Because of how we test implication, we require that the index type contexts use the same names to refer to the same index variables.
    \item The requirement of adding explicit type annotations for index variables and constants that appear in type indices comes from needing to know what width the variable will be when we convert it to a Z3 bitvector.
\end{itemize}

\todo{End of digression}

To fit strengthening and weakening into the type system, we define a subtyping judgment based on implication.
The subtyping judgement says that if an indexed function type $tfi_1$ has a stronger precondition and weaker postcondition than some other indexed function type $tfi_2$, and is otherwise equivalent, then $tfi_1$ is a subtype of $tfi_2$:

\[
    \inferrule{
        \phi_0 \implies \phi_1 \and
        \phi_2 \implies \phi_3
    }{
        ti_1^{*};l_1;\phi_0 \rightarrow ti_2^{*};l_2;\phi_3 <: ti_1^{*};l_1;\phi_1 \rightarrow ti_2^{*};l_2;\phi_2
    }
\]

We then use this in the \name type system by adding a typing rule that allows the indexed function type for a list of instructions to be replaced by a subtype of that indexed function type:

\[
    \inferrule{
        ti_1^{*};l_1;\phi_0 \rightarrow ti_2^{*};l_2;\phi_3 <: ti_1^{*};l_1;\phi_1 \rightarrow ti_2^{*};l_2;\phi_2 \\
        C \vdash e^{*} \rightarrow ti_1^{*};l_1;\phi_1 \rightarrow ti_2^{*};l_2;\phi_2
    }{
        C \vdash e^{*} \rightarrow ti_1^{*};l_1;\phi_0 \rightarrow ti_2^{*};l_2;\phi_3
    }
\]

\subsection{Module Types}
\todo{Functions, globals, tables, and memory, oh my!}