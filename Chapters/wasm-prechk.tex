\chapter{\name}
\label{chp:prechk}
The goal of \name is to eliminate unnecessary dynamic checks.
To accomplish this, it must (1) have instructions that do not require dynamic checks and (2) statically prove that the assumptions of those instructions are met.
\name extends \wasm with new instructions that explicitly do not require dynamic checks, and an indexed type system to reason about the safety of omitting checks.
Intuitively, we are replacing dynamic checks with static checks whenever possible.

\begin{figure}[b]
    $${\begin{stackTL}
        \<block>
        {\begin{stackTL}
            \;(\<ithreetwo>\;\<ithreetwo> \rightarrow \<ithreetwo>)
            \\ (\<teelocal> 0)
            \\ (\<ithreetwo>.\<const> 1)
            \\ (\<getlocal> 0)
            \\ (\<select>)
            \\ (\<ithreetwo>.\<div>)
        \end{stackTL}}
        \\ \<nsend>
    \end{stackTL}}$$

    \caption{An Example of an Unnecessary \wasm check}
    \label{fig:unnecessarycheck}
\end{figure}

Consider the example of a \wasm program with an unnecessary dynamic check in \autoref{fig:unnecessarycheck}.
The program consists of a $\<block>$ instruction that consumes two arguments from the stack and produces onto the stack their quotient if the second argument is non-zero, and the first argument otherwise.
In \wasm, this program would have a dynamic check for division-by-zero inserted for the division instruction ($\<ithreetwo>.\<div>$).
However, this check would be unnecessary since the instructions preceding the division instruction ensures that the second argument is non-zero.
This is guaranteed because the $\<select>$ instruction selects the first value (the local) if the local is non-zero, and otherwise selects the second value ($\<ithreetwo>.\<const> 1$).

In the above example, it is possible to check the necessary precondition of the division instruction (that the second argument is non-zero) statically, rather than dynamically.
\name performs such static checks using an indexed type system.
An indexed type language uses an index language in the type system to encode information within types.
\name's index language must be capable of capturing enough information about a \name program to statically verify the preconditions of \prechk-tagged instructions.

The \name index language is designed to encode linear constraints on program values (the details of they are encoded is discussed in \autoref{subsec:indexlang}).
To do this, we ``shadow'' \name program values using what we call \emph{index variables} to track constraints on and relationships between program values.
Many of these constraints/relationships are written using \wasm operators (\eg $binop$), since they are the predominant way that \wasm values end up being related to each other.
Index variables are associated with program values using \emph{indexed types}, which combine the type information from \wasm: the primitive type $t$ of the value, with the indexed type variable that represents the value in the index language.
Finally, we also use index variables to track local variables (specifically the current value of local variables, since they are mutable and may change) via an \emph{index local store}.

\section{\name Syntax}
The syntax of \name has the same structure as \wasm, but different instructions and richer types.
First, \name introduces four additional instructions, which are referred to as ``\prechk-tagged'' instructions.
Second, \name does not support floating point values or unary operators on integers since they are difficult to reason about (this is explained in more detail in \autoref{chp:implementation}).
While it would be possible to support them, we would have no more type information about them than \wasm, and the focus of this work is on the type information.
\name uses a different representation of types within instructions and functions, as we see in \autoref{subsec:indexlang}.

Recall from \autoref{sec:wasmsemantics} that four \wasm instructions require run-time checks: integer division, indirect function calls, and memory loads and stores.
``\prechk-tagged'' instructions refer to four \name instructions, listed in \autoref{fig:newinstructions}, that are counterparts to these four \wasm instructions.
Intuitively, we add a tag to the instruction to show that it doesn't require run-time checks.
Formally, however, different instructions have different semantics and typing rules, as explained below.

\begin{figure}
    \begin{math}
    \begin{array}{rcl}
        testop_{iN} & ::= & \<eqz> \\
        binop_{iN} & ::= & \<add> \mid \<sub> \mid \<shl> \mid \<or> \mid ... \\
        relop_{iN} & ::= & \<eq> \mid \<ne> \mid \<gt> \mid \<ge> \mid ... \\
    \end{array}
    \end{math}

    \begin{math}
    \begin{array}{rcl}
        e & ::= & \<unreachable> \mid \<nop> \mid \<drop> \mid \<select> \mid \\
        && \<block>\; \hl{\tfi}\; e^{*} \<end> \mid \<loop>\; \hl{\tfi}\; e^{*} \<end> \mid \<if>\; \hl{\tfi}\; e^{*} \<else> e^{*} \<end> \mid \\
        && \<br> i \mid \<brif> i \mid \<brtable> i^{+} \mid \<return> \mid \<call> i \mid \<callindirect> \hl{\tfi} \mid \\
        && \<getlocal> i \mid \<setlocal> i \mid \<teelocal> i \mid \<getglobal> i \mid \\
        && \<setglobal> i \mid t.\<load> (tp\_sx)^{?}\; align\; o \mid t.\<store> tp^{?}\; align\; o \mid \\
        && \<currentmemory> \mid \<growmemory> \mid t.\<const> c \mid \\
        && t.binop_t \mid t.testop_t \mid t.relop_t \mid \\
        \hline
        && \hl{t.\<divpc>} \mid \hl{t.\<callindirectpc>} \mid \\
        && \hl{t.\<loadpc> (tp\_sx)^{?}\; align\;o} \mid \hl{t.\<storepc> tp^{?\;} align\;o} \\
    \end{array}
    \end{math}
    \caption{\name syntax including the four \prechk-tagged instructions}
    \label{fig:newinstructions}
\end{figure}

\subsection{The \name Index Language}
\label{subsec:indexlang}
\name uses an indexed type system.
We use the \name index language to encode constraints on program values within types.
\autoref{fig:itsyntax} shows the syntax for the index type language.
Remember, syntax written in a \tbsf{blue sans serif font} denotes a \wasm keyword.
Below is a quick overview of each metavariable.

\begin{figure}
    \begin{math}
        \begin{array}{rcl}
            t &::= & \<ithreetwo> \mid \<isixfour> \\
            a &::= & IndexVariable \\
            x\;y &::=& a \mid \ti{t}{c} \mid (\<binop>\;x\;y) \mid (\<testop>\;x) \mid (\<relop>\;x\;y) \\
            P &::=& (=\; x \; y) \mid (\text{if}\; P\; P\; P) \mid \neg P \mid P \land P \mid P \lor P \\
            \phi &::=& \circ \mid \phi, \ti{t}{a} \mid \phi, P \\
        \end{array}
    \end{math}
    \caption{Syntax of the \name index type language}
    \label{fig:itsyntax}
\end{figure}

\begin{itemize}
    \item $t$ represents a primitive \wasm type.
    We do not reason about floating point values, so it is either a 32-bit integer (\<ithreetwo>) or a 64-bit integer (\<isixfour>).
    \item $a$ is a type index variable, which is used to track constraints on program values.
    \item $x$ and $y$ are type indices; they can be an index type variable, a constant with an explicit type, or a \wasm operation on a type index.
    \item $P$ is a proposition about type indices which can encode equality constraints on type indices, or combine propositions using common first-order logic operators.
    \item $\phi$ is the type index context which stores index type variable declarations and propositions.
    Essentially, it contains all of the knowledge we have about all of the index variables.
\end{itemize}

\begin{figure}[t]
    \begin{math}
        \begin{array}{rcl}
            ti &::=& \ti{t}{a} \\
            l &::=& ti^{*} \\
            \tfi &::=& ti^{*};l;\phi \rightarrow ti^{*};l;\phi \\
            C &::=& \{
                {\begin{stackTL}
                    \text{func } \; \tfi^{*}, \text{ global } \; (\text{mut}^{?} \; t)^{*}, \text{ table} \; n^{?}, \text{ memory }  m^{?}, \\
                    \text{ local } \; t^{*}, \text{ label}(ti^{*};l;\phi)^{*}, \text{ return}\;(ti^{*};l;\phi)^{? }\}
                \end{stackTL}}
        \end{array}
    \end{math}
    \caption{\name indexed function types}
    \label{fig:tfisyntax}
\end{figure}

Indexed types are used to associate index variables $a$ with values in the program.
\autoref{fig:tfisyntax} shows the form of an indexed type, $ti$, which includes both the type $t$ and an index variable $a$.
In \name, we represent the shape of the stack as a sequence of indexed types $ti^{*}$.

The index local store associates index variables with local variables.
It has an identical form to the stack: a sequence of indexed types to associate index variables with local variables.
We use the shorthand $l$ to refer to the index local store.
The index type context $\phi$ is used to reason about the possible values of computations.
It stores constraints on and between program values tracked by indexed types representing the stack and index local store.

\name uses indexed ``function'' types $\tfi$, which, similar to \wasm's function types, are just a precondition and postcondition.
However, indexed function types include much more information in their precondition and postcondition!
They represent the stack using a sequence of indexed types and track local variables using the index local store, and include $\phi$ which contains constraints about those values.
We see how this information is used in \autoref{subsec:checkelim}.

We retain $C$ to refer to the module type context in \name, although the representation of module types is slightly different.
\wasm function types are replaced with \name indexed function types.
Further, the postconditions in the label stack and return stack are replaced with \name indexed postconditions including indexed types, the local index store, and the index type context.

We can now introduce the \name typing judgement for instructions.
It is similar to the \wasm typing judgment, but uses indexed function types which include much more information by tracking constraints about program values.

\begin{mathpar}
    \boxed{C \vdash e^{*} : \tfi}
\end{mathpar}

Recall that certain \wasm instructions (such as $\<block>$ and $\<callindirect>$) include \wasm function types to declare the expected types of their bodies.
In \name, we replace those function types with indexed function types.

\section{\name Dynamic Semantics}
\name uses the same reduction relation with the same structure as \wasm (explained in detail in \autoref{sec:wasmsemantics}).
All the reduction rules for all of the \name instructions are the same as they are for \wasm, as presented in \autoref{sec:wasmsemantics}, except that indexed function types are used instead of \wasm function types.
We also have four new instructions, for which we introduce new reduction rules.

\label{sec:newinstructions}
\begin{figure}[t]
    \begin{mathpar}
        \boxed{s;v^{*};e^{*} \rightarrow s';v'^{*};e'^{*}}
    \end{mathpar}

    \begin{math}
        \arraycolsep=1.4pt
        \begin{array}{rcl}
            (t.\<const> c_1)\; (t.\<const> c_2)\; t.binop &\hookrightarrow& t.\<const> c \\
            && \text{if } c=binop(c_1,c_2) \\ %% binop

            (t.\<const> c_1)\; (t.\<const> c_2)\; t.binop &\hookrightarrow& \<trap> \\ %% binop to trap
            && otherwise \\

            s;\<callindirect> j &\hookrightarrow_i& s_\text{tab}(i,j) \\
            && \text{if } s_\text{tab}(i,j)_\text{code}=(\<func> tf\; \<local>\; t^{*}\; e^{*}) \\

            s;\<callindirect> j &\hookrightarrow_i& \<trap> \\
            && \text{otherwise} \\

            s;(\<ithreetwo>.\<const> k) &&\\
            (t.\<load> tp\_sx\; align\; o) &\hookrightarrow_i& s;(t.\<const> const_t(b^{*})) \\
            && \text{if } s_\text{mem}(i,k+o,|t|)=b^{*} \\

            s;(\<ithreetwo>.\<const> k) &&\\
            (t.\<load> tp\_sx\; align\; o) &\hookrightarrow_i& \<trap> \\
            && \text{otherwise} \\

            s;(\<ithreetwo>.\<const> k)\; (t.\<const> c) && \\
            (t.\<store> tp\_sx\; align\; o) &\hookrightarrow_i& s';\epsilon \\
            && \text{if }
            {\begin{stackTL}
                s'=s \text{ with}
                \\ \text{mem}(i,k+o,|t|)=bits_t(c)
            \end{stackTL}} \\

            s;(\<ithreetwo>.\<const> k)\; (t.\<const> c) && \\
            (t.\<store> tp\_sx\; align\; o) &\hookrightarrow_i& \<trap> \\
            && \text{otherwise} \\
        \end{array}
    \end{math}
    \caption{\wasm instructions that have preconditions for reduction}
    \label{fig:checked}
\end{figure}

\emph{The formal reason why certain \wasm instructions require run-time checks is because they have preconditions as part of their semantics.}
If the preconditions are not met then those instructions trap to avoid undefined behavior (we've reproduced the reduction rules for those instructions in \autoref{fig:checked}).
The \wasm type system is not expressive enough to ensure these preconditions statically, so they instead must be checked at run-time.
However, the \name type system is capable of statically checking these preconditions.

In \name, ``\prechk-tagged'' instructions can assume that the preconditions on their behavior hold because it is enforced by the \name type system.
This can be seen in the reduction rules for the ``\prechk-tagged'' instructions in Figure \autoref{fig:prechkredux}, where they do not have rules to trap when their preconditions do not hold.
For example, in the $\<divpc>$ rule, the second argument $c_2$ is guaranteed to be non-zero, so there will be no trap on division-by-zero.
\<callindirectpc> can assume that the function that gets pulled from the table $\tfi_2$ has a subtype of the expected type $\tfi$, so it is a valid type for the indirect call (we will go over subtyping in more detail in \autoref{subsec:subtyping}).
The \prechk-tagged memory operations $\<loadpc>$ and $\<storepc>$ can assume that the memory operation takes place inside the memory bounds.

\begin{figure}[t]
    \begin{mathpar}
        \boxed{s;v^{*};e^{*} \rightarrow s';v'^{*};e'^{*}}
    \end{mathpar}

    \begin{math}
        \arraycolsep=1.4pt
        \begin{array}{rcl}
            (t.\<const> c_1)\;(t.\<const> c_2) && \\
            t.\<divpc> & \hookrightarrow & c \\
            && \text{where } c_2 \neq 0 \land c=c_1/c_2 \\
            s;(t.\<const> j) && \\
            t.\<callindirectpc> \tfi & \hookrightarrow_i & \<call> s_{tab}(i,j) \\
            &&\text{where } s_{tab}(i,j) = \\
            && \<func> \tfi_2\; \<local>\; t^{*}\;e^{*} \\
            && \text{and } \tfi_2<:\tfi \\
            s;(\<ithreetwo>.\<const> k) && \\
            (t.\<loadpc> (tp\_sx)^{?}\; a\;o) & \hookrightarrow_i & t.\<const> const_t(b^{*}) \\
            && \text{where } s_{mem}(i,k+o,|t|)=b^{*} \\
            s;(\<ithreetwo>.\<const> k)\;(t.\<const> c) && \\
            (t.\<storepc> tp^{?}\; a\;o) & \hookrightarrow_i & s';\epsilon \\
            && \text{where } s'=s \\
            && \text{with mem}(i,k+o,|t|)=bits_t^{|t|}(c) \\
        \end{array}
    \end{math}
    \caption{Behavior of new \prechk-tagged instructions}
    \label{fig:prechkredux}
\end{figure}

Now, we can rewrite the example from \autoref{fig:unnecessarycheck} to use the \prechk-tagged division instruction, as seen in \autoref{fig:prechkexample}.
Remember that we know the second argument to $\<divpc>$ is guaranteed to be non-zero, so we know the assumption of the $\<divpc>$ instruction ($c_2 \neq 0$) holds.
Since $\<divpc>$ does not require a dynamic check, this program will presumably be faster than the version with the dynamic check.
We still have not shown how we statically ensure that this assumption holds, which we will do in \autoref{subsec:checkelim}.

\begin{figure}[b]
    $${\begin{stackTL}
        \<block>
        {\begin{stackTL}
            \;(\<ithreetwo>\;\<ithreetwo> \rightarrow \<ithreetwo>)
            \\ (\<teelocal> 0)
            \\ (\<ithreetwo>.\<const> 1)
            \\ (\<getlocal> 0)
            \\ (\<select>)
            \\ (\<ithreetwo>.\<divpc>)
        \end{stackTL}}
        \\ \<nsend>
    \end{stackTL}}$$

    \caption{An Example of Using a \name \prechk-tagged Instruction}
    \label{fig:prechkexample}
\end{figure}

\section{The \name Indexed Type System}
\label{sec:typesys}
The \name type system is designed to provide sufficient information to safely eliminate dynamic checks (\ie to ensure that the required preconditions are met to \prechk-tag an instruction).
As explained in ~\ref{subsec:indexlang}, the \name type system can encode constraints on program values in the preconditions and postconditions of instructions.
We will now show how these constraints are added and used.

Recall the form of the \name typing judgement for instructions.
\begin{mathpar}
    \boxed{C \vdash e^{*} : ti_1^{*};l_1;\phi_1 \rightarrow ti_2^{*};l_2;\phi_2}
\end{mathpar}

Under $C$, the module type context, $e^{*}$ has the precondition $ti_1^{*};l_1;\phi_1$ and postcondition $ti_2^{*};l_2;\phi_2$.
We sometimes use the metavariable abbreviation $\tfi ::= ti_1^{*};l_1;\phi_1 \rightarrow ti_2^{*};l_2;\phi_2$ as shorthand for the precondition and postcondition of an instruction.

As in \wasm, \name generally has two kinds of typing rules.
Most rules are for inferring or checking the types of instructions (in which case $e^{*}$ will be a single instruction).
There are also a few rules to compose together instruction sequences.
We present the typing rules mixed with discussion of those rules.
The typing judgment definition in its entirety is reproduced in the appendix \autoref{chp:completejudgment}.

Here are some of the simpler rules.
These rules don't use or modify index type information.
\refrule{Unreachable} accepts any precondition and guarantees any postcondition since it just causes a trap.
In \refrule{Nop}, no changes are made from the precondition to the post condition because the instruction does nothing.
\refrule{Drop} consumes the top value from the stack (without caring about its type) and does not change the local index store or index type context.
\begin{mathpar}
    \inferrule*[right=\defrule{Unreachable}]{ }{ %% unreachable
        C \vdash \<unreachable> : ti_1^{*};l_1;\phi_1 \rightarrow ti_2^{*};l_2;\phi_2
    }

    \inferrule*[right=\defrule{Nop}]{ }{ %% nop
        C \vdash \<nop> : \epsilon;l;\phi \rightarrow \epsilon;l;\phi
    }

    \inferrule*[right=\defrule{Drop}]{ }{ %% drop
        C \vdash \<drop> : \ti{t}{a};l;\phi \rightarrow \epsilon;l;\phi
    }
\end{mathpar}

The constant instruction is a simple example of how indexed types work.
\refrule{Const} adds a new indexed type onto the stack to track the new program variable $\ti{t}{a}$, declares the new indexed type in the index type context $\phi$ (the $\ti{t}{a}$ part of $\phi,\ti{t}{a},(= a\; \ti{t}{c})$), and constrains that indexed type to be equal to the constant in $\phi$ (the $(= a\; \ti{t}{c})$ part of $\phi,\ti{t}{a},(= a\; \ti{t}{c})$).
We require $a$ to be fresh using the premise $a_3 \not\in \phi$, so that we know $a$ is not constrained/referenced anywhere in the precondition.
This is a common pattern to see in rules which introduce new index variables.
Since \<const> does not change or reference the local variables, the local index store $l$ is unchanged between the precondition and postcondition.
\begin{mathpar}
    \inferrule*[right=\defrule{Const}]{ a \not\in \phi }{ %% const
        C \vdash t.\<const> c : \epsilon;l;\phi \rightarrow \ti{t}{a};l;\phi,\ti{t}{a},(= a \ti{t}{c})
    }
\end{mathpar}

There are several different kinds of operations, but they all work similarly.
The binary operator instruction adds constraints between new and old program values, since the result of the instruction is a new program value, while the consumed values may already be constrained.
A binary operation consumes two values from the stack, which have associated indexed types $\ti{t}{a_1}$ and $\ti{t}{a_2}$, and produces a value which is associated with the fresh indexed type $\ti{t}{a_3}$.
The index type declaration $\ti{t}{a_3}$ is added to the index type context $\phi$ and $a_3$ is constrained to be equal to the binary operator applied to the index variables that correspond to the input $(= a_3\;(\|binop\|\;a_1\;a_2)$.
As a side note, we use $\|binop\|$ to indicate that we are moving the $binop$ (or relop or testop) from \name to the index language, where it will be interpreted by the semantics of the index language.
Binary operators do not affect or use local variables, so the local index store. $l$, is the same in the precondition and postcondition.
\begin{mathpar}
    \inferrule*[right=\defrule{Binop}]{ a_3 \not\in \phi }{ %% binop
        C \vdash t.binop :
        {\begin{stackTL}
            \ti{t}{a_1}\;\ti{t}{a_2};l;\phi
            \\ \rightarrow \ti{t}{a_3};l;\phi,\ti{t}{a_3},(= a_3\;(\|binop\|\;a_1\;a_2))
        \end{stackTL}}
    }

    \inferrule*[right=\defrule{Testop}]{ a_3 \not\in \phi }{ %% testop
        C \vdash t.testop :
        {\begin{stackTL}
            \ti{t}{a_1}\;l;\phi
            \\ \rightarrow \ti{\<ithreetwo>}{a_2};l;\phi,\ti{t}{a_2},(= a_2\;(\|testop\|\;a_1))
        \end{stackTL}}
    }

    \inferrule*[right=\defrule{Relop}]{ a_3 \not\in \phi }{ %% relop
        C \vdash t.relop :
        {\begin{stackTL}
            \ti{t}{a_1}\;\ti{t}{a_2};l;\phi
            \\ \rightarrow \ti{t}{a_3};l;\phi,\ti{t}{a_3},(= a_3\;(\|relop\|\;a_1\;a_2))
        \end{stackTL}}
    }
\end{mathpar}

\refrule{Select} constrains indexed types in a rather complex way.
Select consumes three values from the stack, it returns the second value if the third value is zero, and otherwise returns the first value (similar to C's ternary operator).
We use the type-level ``if'' to allow the constraint on the result to depend on the third value consumed: $(\text{if}\; (= a\; \ti{\<ithreetwo>}{0})\; (= a_3\;a_2)\; (= a_3\;a_1))$.

\begin{mathpar}
    \inferrule*[right=\defrule{Select}]{a_3 \not\in \phi}{ %% select
        C \vdash \<select> : {\begin{stackTL}
            \ti{t}{a_1}\;\ti{t}{a_2}\;\ti{i32}{a};l;\phi
            \\ \rightarrow \ti{t}{a_3};l;\phi,
            {\begin{stackTL}
                \ti{t}{a_3},
                \\ (\text{if}\; (= a\; \ti{\<ithreetwo>}{0})\; (= a_3\;a_2)\; (= a_3\;a_1))
            \end{stackTL}}
        \end{stackTL}}
    }
\end{mathpar}

The rules for the three different kinds of blocks (\<block>, \<loop>, and \<if>) are similar to \wasm.
They simply ensure that the interior instruction sequence has the expected type under the context with the expected postcondition (or precondition in the case of \<loop>) appended to the local stack.
In \name, \<if> blocks make extra assumptions about the consumed value in the subsequences (that it is non-zero in the first sequence and zero in the second), because those constraints must be true for that sequence to be executed.
While \<if> and \<block> append their postcondition to the label stack for typechecking branching instructions within the block, \<loop> appends its precondition because branching to a loop means running the loop again.

\begin{mathpar}
    \inferrule*[right=\defrule{Block}]{ %% block
        C_2,\text{label } (ti_2^{*};l_2;\phi_2) \vdash e^{*} : ti_1^{*};l_1;\phi_1 \rightarrow ti_2^{*};l_2;\phi_2 \\
    }
    {
        C \vdash \<block>\; (ti_1^{*};l_1;\phi_1 \rightarrow ti_2^{*};l_2;\phi_2)\; e^{*} \<end> : ti_1^{*};l_1;\phi_1 \rightarrow ti_2^{*};l_2;\phi_2
    }

    \inferrule*[right=\defrule{Loop}]{ %% loop
        C_2,\text{label } (ti_1^{*};l_1;\phi_1)^{*} \vdash e^{*} : ti_1^{*};l_1;\phi_1 \rightarrow ti_2^{*};l_2;\phi_2 \\
    }
    {
        C \vdash \<loop>\; (ti_1^{*};l_1;\phi_1 \rightarrow ti_2^{*};l_2;\phi_2)\; e^{*} \<end> : ti_1^{*};l_1;\phi_1 \rightarrow ti_2^{*};l_2;\phi_2
    }

    \inferrule*[right=\defrule{If}]{ %% if
        C_2,\text{label } (ti_2^{*};l_2;\phi_2) \vdash e_1^{*} : ti_1^{*};l_1;\phi_1, \neg(= a\; \ti{\<ithreetwo>}{0}) \rightarrow ti_2^{*};l_2;\phi_2 \\
        C_2,\text{label } (ti_2^{*};l_2;\phi_2) \vdash e_2^{*} : ti_1^{*};l_1;\phi_1, (= a\; \ti{\<ithreetwo>}{0})) \rightarrow ti_2^{*};l_2;\phi_2 \\
    }
    {
        C \vdash \<if>\; (ti_1^{*};l_1;\phi_1 \rightarrow ti_2^{*};l_2;\phi_2)\; e_1^{*} \<else> e_2^{*} \<end> : ti_1^{*};l_1;\phi_1 \rightarrow ti_2^{*};l_2;\phi_2
    }
\end{mathpar}

One thing to note is that all three of these rules include their expected preconditions and postconditions as part of their syntax.
We consider the index variables in these indexed function types to be unification variables rather than literals, allowing them to match any literal as long as the types unify.
Intuitively, this is very similar to alpha equivalence, where the precondition matches any preceding postcondition with the same structure as long as the variable can be renamed to match.
The postcondition appended to the label stack also has unification variables instead of the supplied literals.

The rules for branching instructions and return are similar to \wasm.
However, $\<brif>$ adds the assumption that the consumed value is zero to its postcondition.
This assumption can be safely added because the value must be zero for execution to continue without a branch occurring.
If the consumed value is constrained to be non-zero in the indexed type system, then this will cause a contradiction in the constraints of the index type context $\phi$.
However, that is fine since this means that no instructions following the $\<brif>$ will be executed.
Also remember the above note that the postconditions on the label stack contain unification variables, not literals.

Recall from \autoref{sec:wasmsemantics} that $\<brtable>$ branches to one of many different labels.
Thus, we must ensure that every possible branching postcondition to which it might branch is implied by the precondition.

\begin{mathpar}
    \inferrule*[right=\defrule{Br}]{ %% br
        C_{\text{label}}(i) = ti^{*};l_1;\phi_1
    }
    {
        C \vdash \<br> i : ti_1^{*}\;ti^{*};l_1;\phi_1 \rightarrow ti_2^{*};l_2;\phi_2
    }

    \inferrule*[right=\defrule{Return}]{ %% return
        C_{\text{return}} = ti^{*};l_1;\phi_1
    }
    {
        C \vdash \<return> : ti_1^{*}\;ti^{*};l_1;\phi_1 \rightarrow ti_2^{*};l_2;\phi_2
    }

    \inferrule*[right=\defrule{Br-If}]{ %% br_if
        C_{\text{label}}(i) = ti^{*};l_1;\phi_1,\neg(= a\; \ti{\<ithreetwo>}{0})
    }
    {
        C \vdash \<brif> i : ti^{*}\;\index{i32}{a};l_1;\phi_1 \rightarrow ti^{*};l_1;\phi_1,(= a\; \ti{\<ithreetwo>}{0})
    }

    \inferrule*[right=\defrule{Br-Table}]{ %% br_table
        (C_{\text{label}}(i) = ti^{*};l_1;\phi_i)^{+} \and
        (\phi_1 \implies \phi_i)^n
    }
    {
        C \vdash \<brtable> i^{+} : ti_1^{*}\;ti^{*}\;\index{i32}{a};l_1;\phi_1 \rightarrow ti_2^{*};l_2;\phi_2
    }
\end{mathpar}

Recall that functions are declared within the module with a specific indexed function type $\tfi$, that is a precondition and postcondition.
These declared indexed function types are placed inside the module type context $C$.
Direct function calls $\<call> i$ have the same type as the declared indexed function type of the function they are calling with two differences.
First, the local index store is unchanged, since the called function will have been turned into a closure that operates on separate local variables in a local block.
Second, the index type context in the postcondition of the call is extended with the declarations and constraints from the precondition of the call.
The precondition and postcondition of a function can only contain constraints about the arguments supplied to that function, so simply copying the postcondition of the function would result in the loss of information about all other index variables.

Indirect function calls $\<callindirect> ti_1^{*};l_1;\phi_1 \rightarrow ti_2^{*};l_2;\phi_2$ include the expected indexed function type $ti_1^{*};l_1;\phi_1 \rightarrow ti_2^{*};l_2;\phi_2$ provided as part of their syntax (the same note about index variables being unification variables from above holds).
Remember that indirect function calls perform a run time typecheck against the closure that they end up calling, so we assume statically that the check will proceed because if it does not the program will trap (\<trap> satisfies any $\tfi$, including the one for the indirect call) and not be able to do any harm.
The same two differences described above between the expected indexed function type $\tfi$ and the type of the $\<callindirect> \tfi$ instruction also hold.

\begin{mathpar}
    \inferrule*[right=\defrule{Call}]{ %% call
        C_\text{func}(i) = ti_1^{*};l_1;\phi_1 \rightarrow ti_2^{*};l_2;\phi_2
    }
    {
        C \vdash \<call> i : ti_1^{*};l;\phi_1 \rightarrow ti_2^{*};l;\phi_1,\phi_2
    }

    \inferrule*[right=\defrule{Call-Indirect}]{ %% call_indirect
        C_\text{table}(i) = (j, \tfi_2^{*}) \and
    }
    {
        C\;
        {\begin{stackTL}
            \vdash \<callindirect>  ti_1^{*};l_1;\phi_1 \rightarrow ti_2^{*};l_2;\phi_2
            \\ : ti_1^{*}\;\ti{i32}{a};l;\phi_1 \rightarrow ti_2^{*};l;\phi_1,\phi_2
        \end{stackTL}}
    }
\end{mathpar}

The only instructions that actually mutate the local index store are those that operate on local variables.
$\<getlocal>$ produces a fresh indexed type $\ti{t}{a_2}$ that is constrained to be equal to the index variable associated with the local being retrieved.
$\<setlocal>$ works in the reverse direction, replacing the index variable associated with the local being set.
Because $\<setlocal>$ reasons about local variables, which are not part of the instruction sequence (unlike values on the stack), we can copy the index variable instead of creating a fresh one and constraining it to be equal like for $\<getlocal>$
Finally, $\<teelocal>$ is effectively a combined $\<setlocal>$ and $\<getlocal>$ that consumes and immediately regurgitates a value, like the Unix tool ``tee''.
Thus, the typing rule is similarly a combination of the $\<setlocal>$ and $\<getlocal>$ rules, where the indexed type from the stack replaces the local variable indexed type, and a fresh indexed type is produced that is constrained to be equal to the consumed index variable.
\begin{mathpar}
    \inferrule*[right=\defrule{Get-Local}]{ %% get_local
        C_{\text{local}}(i) = t \and
        l(i) = \ti{t}{a} \and
        a_2 \not\in \phi
    }
    {
        C \vdash \<getlocal> i : \epsilon;l;\phi \rightarrow \ti{t}{a_2};l;\phi,\ti{t}{a_2},(= a_2 \; a)
    }

    \inferrule*[right=\defrule{Set-Local}]{ %% set_local
        C_{\text{local}}(i) = t \and
        l_2 = l_1[i := \ti{t}{a}] \and
    }
    {
        C \vdash \<setlocal> i : \ti{t}{a};l_1;\phi \rightarrow \epsilon;l_2;\phi
    }

    \inferrule*[right=\defrule{Tee-Local}]{ %% tee_local
        C_{\text{local}}(i) = t \and
        l_2 = l_1[i := \ti{t}{a}] \and
        a_2 \not\in \phi
    }
    {
        C \vdash \<teelocal> i : \ti{t}{a};l_1;\phi \rightarrow \ti{t}{a_2};l_2;\phi,\ti{t}{a_2},(= a_2 \; a)
    }
\end{mathpar}

Instructions for getting and setting globals produce and consume unconstrained values respectively.
Global variables are difficult to reason about in the type system since they are different between modules.
At compile-time, before linking, a module has no information about globals from another module which would be necessary for reasoning about the types of functions imported from the other module.
Therefore, we do not track index variables for globals (we just treat them as unconstrained values when they are introduced onto the stack by \<getglobal>).
We do still statically ensure the same properties as \wasm: that the value is of the correct \wasm type and in the case of setting a global variable that the global variable is mutable (has the $mut$ flag in its type).
\begin{mathpar}
    \inferrule*[right=\defrule{Get-Global}]{ %% get_global
        C_\text{global}(i) = \text{mut}^{?}\; t \and
        a \not\in \phi
    }
    {
        C \vdash \<getglobal> i : \epsilon;l;\phi \rightarrow \ti{t}{a};l;\phi,\ti{t}{a}
    }

    \inferrule*[right=\defrule{Set-Global}]{ %% set_global
        C_\text{global}(i) = \text{mut } t
    }
    {
        C \vdash \<setglobal> i : \ti{t}{a};l;\phi \rightarrow \epsilon;l;\phi
    }
\end{mathpar}

The typing rules for memory instructions are very similar to \wasm as we do not reason about the contents of memory or how its size can change throughout a program.
As in \wasm, there are many small details related to how exactly values are loaded and stored that are not particularly important to the understanding of the type system, but they are explained with the reduction rules for these values in \autoref{sec:wasmsemantics}.
One thing that does not appear in the \wasm reduction rules but mysteriously appears in the typing rules without much explanation is $align$.
It is checked against the size of the type of the value being stored/loaded $|t|$ (or optionally $|tp|$, which should be less than $|t|$) in the premise $2^{align} \leq (|tp| <)^{?} |t|$.

\begin{mathpar}
    \inferrule*[right=\defrule{Mem-Load}]{ %% memory load
        C_\text{memory} = n \and
        2^{align} \leq (|tp| <)^{?} |t| \and
        a_2 \not\in \phi
    }
    {
        C \vdash t.\<load> (tp\_sx)^{?}\; align\; o : \ti{\<ithreetwo>}{a_1};l;\phi \rightarrow \ti{t}{a_2};l;\phi,\ti{t}{a_2}
    }

    \inferrule*[right=\defrule{Mem-Store}]{ %% memory store
        C_\text{memory} = n \and
        2^{align} \leq (|tp| <)^{?} |t|
    }
    {
        C \vdash t.\<store> tp^{?}\; align\; o : \ti{\<ithreetwo>}{a_1}\;\ti{t}{a_2};l;\phi \rightarrow \epsilon;l;\phi
    }

    \inferrule*[right=\defrule{Current-Memory}]{ %% current mem
        C_\text{memory} = n \and
        a \not\in \phi
    }
    {
        C \vdash \<currentmemory> : \epsilon;l;\phi \rightarrow \ti{\<ithreetwo>}{a};l;\phi,\ti{\<ithreetwo>}{a}
    }

    \inferrule*[right=\defrule{Grow-Memory}]{ %% grow mem
        C_\text{memory} = n \and
        a_2 \not\in \phi
    }
    {
        C \vdash \<growmemory> : \ti{\<ithreetwo>}{a_1};l;\phi \rightarrow \ti{\<ithreetwo>}{a_2};l;\phi,\ti{\<ithreetwo>}{a_2}
    }
\end{mathpar}

The last rules are the ones that can be used to compose sequences of instructions.
The first rule is for the empty instruction sequence $\epsilon$, which, similar to \wasm, simply has the same precondition and postcondition $\epsilon;l;\phi$.
Second, we have \refrule{Stack-Poly} to add stack polymorphism (see \autoref{subsec:stackpoly}).
Third, there is a rule to compose a sequence of instructions $e_1^{*}$ with another instruction $e_2$.
\begin{mathpar}
    \inferrule*[right=\defrule{Empty}]{ %% empty
    }
    {
        C \vdash \epsilon : \epsilon;l;\phi \rightarrow \epsilon;l;\phi
    }

    \inferrule*[right=\defrule{Stack-Poly}]{ %% extra vars
        C \vdash e^{*} : ti_1^{*};l_1;\phi_1 \rightarrow ti_2^{*};l_2;\phi_2
    }
    {
        C \vdash e^{*} : ti^{*}\;ti_1^{*};l_1;\phi_1 \rightarrow ti^{*}\;ti_2^{*};l_2;\phi_2
    }

    \inferrule*[right=\defrule{Composition}]{ %% combine
        C \vdash e_1^{*} : ti_1^{*};l_1;\phi_1 \rightarrow ti_2^{*};l_2;\phi_2 \\
        C \vdash e_2 : ti_2^{*};l_2;\phi_2 \rightarrow ti_3^{*};l_3;\phi_3
    }
    {
        C \vdash e_1^{*}\;e_2 : ti_1^{*};l_1;\phi_1 \rightarrow ti_3^{*};l_3;\phi_3
    }
\end{mathpar}

\subsection{Subtyping, Implication, and Constraint Satisfaction}
\label{subsec:subtyping}
One issue with adding the index type context $\phi$ to preconditions and postconditions is that the postcondition of one instruction and the precondition of the next instruction might not match up exactly.
For example, one instruction may ensure a value is greater than ten, but the next just wants the value to be greater than zero.
Intuitively, if a value, ``x'', is greater than ten it must also be greater than zero, and we want the \name type system to be able to figure this out as well.
However, computers as of yet are unable to use intuition, so we must instead formalize this.

Our formalization of this problem is to allow \emph{strengthening} preconditions and \emph{weakening} postconditions.
Strengthening and weakening is based on implication ($\implies$).
We say that $\phi_1 \implies \phi_2$ when the following holds: if $\phi_1$ is satisfied, then $\phi_2$ must also be satisfied.
If $\phi_1 \implies \phi_2$, then we consider $\phi_1$ to be stronger than $\phi_2$, and $\phi_2$ to be weaker than $\phi_1$.
This solves the aforementioned problem because we can weaken ``x is greater than 10'' to ``x is greater than 0'' (or equivalently strengthen ``x is greater than 0'' to ``x is greater than 10'').

To fit strengthening and weakening into the type system, we define a subtyping judgment based on implication.
We are essentially parameterizing our typing judgment with the implication relation.
As an aside, we show that this is a practical thing to do and that such a relation exists by implementing such an implication relation using Z3 (see \autoref{subsec:z3}).
The \refrule{Implies} says that if an indexed function type $\tfi_1$ has a stronger precondition and weaker postcondition than some other indexed function type $\tfi_2$, and is otherwise equivalent, then $\tfi_1$ is a subtype of $\tfi_2$ since it can safely be used in place of $\tfi_2$.

\begin{mathpar}
    \inferrule*[right=\defrule{Implies}]{
        \phi_0 \implies \phi_1 \and
        \phi_2 \implies \phi_3
    }{
        ti_1^{*};l_1;\phi_1 \rightarrow ti_2^{*};l_2;\phi_2 <: ti_1^{*};l_1;\phi_0 \rightarrow ti_2^{*};l_2;\phi_3
    }
\end{mathpar}

We then use this in the \name type system by adding a typing rule that allows the indexed function type for a list of instructions to be replaced by a subtype of that indexed function type.

\[
    \inferrule*[right=\defrule{Subtyping}]{
        ti_1^{*};l_1;\phi_1 \rightarrow ti_2^{*};l_2;\phi_2 <: ti_1^{*};l_1;\phi_0 \rightarrow ti_2^{*};l_2;\phi_3 \\
        C \vdash e^{*} \rightarrow ti_1^{*};l_1;\phi_1 \rightarrow ti_2^{*};l_2;\phi_2
    }{
        C \vdash e^{*} \rightarrow ti_1^{*};l_1;\phi_0 \rightarrow ti_2^{*};l_2;\phi_3
    }
\]

\subsection{Using Types for Check Elimination}
\label{subsec:checkelim}
In Section \ref{sec:newinstructions} we explained that \prechk-tagged instructions do not need dynamic checks because of the static guarantees of the \name type system.
Here, we see how the \name type system provides those guarantees by looking at the typing rules for each of the \prechk-tagged instructions.

Integer division simply requires that the second argument is non-zero.
The premise $\phi \implies \neg(=\ a_2\ 0)$ requires that the index constraints satisfy the proposition $a_2 \neq 0$ for the pre-checked instruction to be safe.
Therefore, since a divide-by-zero is provably absent, it is safe to use the \prechk-tagged division instruction.
As an aside, recall that $a_3 \not\in \phi$ ensures that $a_3$ is fresh.
\begin{mathpar}
    \inferrule*[right=\defrule{Div-Prechk}]{
        \phi \implies \neg(=\ a_2\ 0) \and
        a_3 \not\in \phi
    }{
        C \vdash t.\<divpc> :
        {\begin{stackTL}
            \ti{t}{a_1}\;\ti{t}{a_2};l;\phi
            \\ \rightarrow \ti{t}{a_3};l;\phi,\ti{t}{a_3},(= a_3\;(\|div\|\;a_1\;a_2))
        \end{stackTL}}
    }
\end{mathpar}

Tagging memory loads and stores with \prechk requires ensuring that the memory index is valid.
Since \wasm and \name use linear memory, which is a contiguous block of memory, we simply have to ensure that the index is within those bounds.
The initial memory size is the number of $64$ Ki pages ($65,536$ bytes), so we check that the constraints in the index type context ensure that the memory index plus the static offset is between $0$ and $65,536-width$.
We use $width$ as a shorthand to denote the number of bytes that is being stored/loaded, it is equal to $|t|/8$ if $tp^{?}=\epsilon$, and otherwise equal to $|tp|/8$.

Unfortunately, while the size of memory may be grown during program execution, we are currently unable to reason about changing memory size.
Therefore, we just use the initial memory size.
\begin{mathpar}
    \inferrule*[right=\defrule{Load-Prechk}]{ %% memory load
        C_\text{memory} = n \and
        2^{align} \leq (|tp| <)^{?} |t| \and
        a_3 \not\in \phi \\
        \phi \implies
        {\begin{stackTL}
            (\<ge> (\<add> a_1\; \ti{\<ithreetwo>}{o}) \ti{\<ithreetwo>}{0}),
            \\ (\<le> (\<add> a_1\; (\<add> \ti{\<ithreetwo>}{o+width}))\; \ti{\<ithreetwo>}{n*64 \text{Ki}})
        \end{stackTL}}
    }
    {
        C \vdash t.\<loadpc> (tp\_sx)^{?}\; align\; o :
        {\begin{stackTL}
            \ti{\<ithreetwo>}{a_1};l;\phi
            \\ \rightarrow \ti{t}{a_2};l;\phi,\ti{t}{a_2}
        \end{stackTL}}
    }

    \inferrule*[right=\defrule{Store-Prechk}]{ %% memory store
        C_\text{memory} = n \and
        2^{align} \leq (|tp| <)^{?} |t| \\
        \phi \implies
        {\begin{stackTL}
            (\<ge> (\<add> a_1\; \ti{\<ithreetwo>}{o})\; \ti{\<ithreetwo>}{0}),
            \\ (\<le> (\<add> a_1\; (\<add> \ti{\<ithreetwo>}{o+width}))\; \ti{\<ithreetwo>}{n*64\text{Ki}})
        \end{stackTL}}
    }
    {
        C \vdash t.\<storepc> tp^{?}\; align\; o : \ti{\<ithreetwo>}{a_1}\;\ti{t}{a_2};l;\phi \rightarrow \epsilon;l;\phi
    }
\end{mathpar}

Indirect function calls in \wasm require a dynamic check to ensure that the index into the table points to a function of a suitable type (recall the explanation of tables and \<callindirect> from \autoref{sec:wasmsemantics}).
Proving the safety of an indirect function call involves showing that every possible function that could be called will not cause a run-time type error.
We ensure this by requiring that the type of every function at every possible index value has a subtype of the expected type: $\forall 0 < i \leq n. (\phi \implies \neg (= \ti{\<ithreetwo>}{i}\; a)) \lor \tfi s(i) <: \tfi$ where $\tfi s=(\tfi_2 ...)$.
The $\forall$ and $\lor$ (as in $(\phi \implies \neg (= \ti{\<ithreetwo>}{i}\; a)) \lor\; \tfi s(i) <: \tfi$) in this case are at the meta level and not within the index language.
Further, we must show that the provided table index is within the table boundaries: $\phi \implies (\<gt>\; n\; a) \land (\<le> \ti{\<ithreetwo>}{0}\; a)$.
\begin{mathpar}
    \inferrule*[right=\defrule{Call-Indirect-Prechk}]{ %% call_indirect
        C_{table}(i) = (n, (\tfi_2 ...)) \\
        \phi \implies (\<gt>\; n\; a) \land (\<le> \ti{\<ithreetwo>}{0}\; a) \\
        \mathit{tfis}=(\tfi_2 ...) \\
        \tfi = ti_1^{*};l_1;\phi_1 \rightarrow ti_2^{*};l_2;\phi_2 \\
        \forall 0 < i \leq n.\; (\phi \implies \neg (= \ti{\<ithreetwo>}{i}\; a)) \lor\; \mathit{tfis}(i) <: \tfi
    }
    {
        C \vdash \<callindirectpc> \tfi :
        {\begin{stackTL}
            ti_1^{*}\;\ti{i32}{a};l;\phi_1
            \\ \rightarrow ti_2^{*};l;\phi_1,\phi_2
        \end{stackTL}}
    }
\end{mathpar}

\paragraph{An Example of Using Types for Check Elimination}
\label{elimexample}
Here we present a short contrived example of using types for check elimination, based on the example from \autoref{fig:prechkexample}.
We are typechecking a $\<divpc>$.
First, we give the module type context $C_1$, which contains one local variable, which is an $\<ithreetwo>$, and the instruction sequence we are typing, which is a safe division happening inside of a block (\autoref{fig:prechkexample}).
We also use the shorthand $C_2$ for $C_1$ extended with the label postcondition for the instructions inside the block.

\begin{math}
    \begin{array}{rcl}
        C_1 &=& \{ {\begin{stackTL}
        \text{func } \epsilon, \text{ global } \epsilon, \text{ table } \epsilon, \text{ memory } \epsilon,
        \\ \text{local } \<ithreetwo>, \text{ label } \epsilon, \text{ return } \epsilon\}
        \end{stackTL}} \\

        C_2 &=& \{ {\begin{stackTL}
        \text{func } \epsilon, \text{ global } \epsilon, \text{ table } \epsilon, \text{ memory } \epsilon,
        \\ \text{local } \<ithreetwo>, \text{ label } (\ti{\<ithreetwo>}{a_0};\ti{\<ithreetwo>}{a_2};\circ), \text{ return } \epsilon\}
        \end{stackTL}} \\
    \end{array}
\end{math}

The block takes two integers, and, using the local as temporary storage, either divides the first by the second, or the first by 1 if the second is 0.
In the example we build up type derivations to reach a typing derivation for the whole block.
We first state the rule that we will use, than give the derivation (in many cases we apply \refrule{Stack-Poly} inline for brevity).
Typechecking the example relies on $\<select>$, where the second argument $(\<ithreetwo>.\<const> 1)$ is chosen if the first argument (and the conditional) $\<getlocal> 0$ is equal to zero, so the result must be non-zero.

\begin{enumerate}
    \item \refrule{Tee-Local} and \refrule{Stack-Poly}

        Note that $\phi_1 = \circ,\ti{\<ithreetwo>}{a_1},\ti{\<ithreetwo>}{a_2}$, and $\phi_2 = \phi_1,(\<ithreetwo>\; a_4),(= a_4\; a_2)$.
        $$\infer{
            C_{2\text{local}}(0)=\<ithreetwo> \\
            \ti{\<ithreetwo>}{a_2} = \ti{\<ithreetwo>}{a_3}[0 := \ti{\<ithreetwo>}{a_2}] \\
            a_4 \not\in \phi_1 \\
        }{
            C_2 \vdash \<teelocal> 0 :
            {\begin{stackTL}
                \ti{\<ithreetwo>}{a_1}\;\ti{\<ithreetwo>}{a_2};\ti{\<ithreetwo>}{a_3};\phi_1
                \\ \rightarrow \ti{\<ithreetwo>}{a_1}\;\ti{\<ithreetwo>}{a_4};\ti{\<ithreetwo>}{a_2};\phi_2
            \end{stackTL}}
        }$$

    \item \refrule{Const} and \refrule{Stack-Poly}

        Note that $\phi_3 = \phi_2,(= a_4\; a_2),(\<ithreetwo>\; a_5),(= a_5\;\ti{\<ithreetwo>}{1})$.
        $$\infer{
            a_5 \not\in \phi_2 \\
        }{
            C_2 \vdash \<ithreetwo>.\<const> 1 :
            {\begin{stackTL}
                \ti{\<ithreetwo>}{a_1}\;\ti{\<ithreetwo>}{a_4};\ti{\<ithreetwo>}{a_2};\phi_2
                \\ \rightarrow \ti{\<ithreetwo>}{a_1}\;\ti{\<ithreetwo>}{a_4}\;\ti{\<ithreetwo>}{a_5};\ti{\<ithreetwo>}{a_2};\phi_3
            \end{stackTL}}
        }$$

    \item \refrule{Composition}
        $$\infer{
            1. \\ 2.
        }{
            C_2\;
            {\begin{stackTL}
                \vdash (\<teelocal> 0)\; (\<ithreetwo>.\<const> 1)
                \\ :
                {\begin{stackTL}
                    \ti{\<ithreetwo>}{a_1}\;\ti{\<ithreetwo>}{a_2};\ti{\<ithreetwo>}{a_3};\phi_1
                    \\ \rightarrow \ti{\<ithreetwo>}{a_1}\;\ti{\<ithreetwo>}{a_4}\;\ti{\<ithreetwo>}{a_5};\ti{\<ithreetwo>}{a_2};\phi_3
                \end{stackTL}}
            \end{stackTL}}
        }$$

    \item \refrule{Get-Local} and \refrule{Stack-Poly}

        Note that $\phi_4 = \phi_3,(\<ithreetwo>\; a_6),(= a_6\;a_2)$.
        $$\infer{
            a_6 \not\in \phi_3 \\
        }{
            C_2 \vdash \<getlocal> 0 :
            {\begin{stackTL}
                \ti{\<ithreetwo>}{a_1}\;\ti{\<ithreetwo>}{a_4}\;\ti{\<ithreetwo>}{a_5};\ti{\<ithreetwo>}{a_2};\phi_3
                \\ \rightarrow \ti{\<ithreetwo>}{a_1}\;\ti{\<ithreetwo>}{a_4}\;\ti{\<ithreetwo>}{a_5}\;\ti{\<ithreetwo>}{a_6};\ti{\<ithreetwo>}{a_2};\phi_4
            \end{stackTL}}
        }$$

    \item \refrule{Composition}

        Note that $\phi_4 = \phi_3,(\<ithreetwo>\; a_6),(= a_6\;a_2)$.
        $$\infer{
            3. \\ 4.
        }{
            C_2\;
            {\begin{stackTL}
                \vdash (\<teelocal> 0)\; (\<ithreetwo>.\<const> 1)\; (\<getlocal> 0)
                \\ :
                {\begin{stackTL}
                    \ti{\<ithreetwo>}{a_1}\;\ti{\<ithreetwo>}{a_2};\ti{\<ithreetwo>}{a_3};\phi_1
                    \\ \rightarrow \ti{\<ithreetwo>}{a_1}\;\ti{\<ithreetwo>}{a_4}\;\ti{\<ithreetwo>}{a_5}\;\ti{\<ithreetwo>}{a_6};\ti{\<ithreetwo>}{a_2};\phi_4
                \end{stackTL}}
            \end{stackTL}}
        }$$

    \item \refrule{Select} and \refrule{Stack-Poly}

        Note that $\phi_5 = \phi_4,(\<ithreetwo>\; a_7),(\text{if }(= a_6\; \ti{\<ithreetwo>}{0})\;(= a_7\;a_5) (= a_7\;a_4))$.
        $$\infer{
            a_7 \not\in \phi_5
        }{
            C_2\;
            {\begin{stackTL}
                \vdash \<select>
                \\ :
                {\begin{stackTL}
                    \rightarrow \ti{\<ithreetwo>}{a_1}\;\ti{\<ithreetwo>}{a_4}\;\ti{\<ithreetwo>}{a_5}\;\ti{\<ithreetwo>}{a_6};\ti{\<ithreetwo>}{a_2};\phi_4
                    \\ \rightarrow (\ti{\<ithreetwo>}{a_1}\;\ti{\<ithreetwo>}{a_7};\ti{\<ithreetwo>}{a_2};\phi_5
                \end{stackTL}}
            \end{stackTL}}
        }$$

    \item \refrule{Composition}

        $$\infer{
            5. \\ 6.
        }{
            C_2\;
            {\begin{stackTL}
                \vdash (\<teelocal> 0)\; (\<ithreetwo>.\<const> 1)\; (\<getlocal> 0)\; (\<select>)
                \\ :
                {\begin{stackTL}
                    \ti{\<ithreetwo>}{a_1}\;\ti{\<ithreetwo>}{a_2};\ti{\<ithreetwo>}{a_3};\phi_1
                    \\ \rightarrow (\ti{\<ithreetwo>}{a_1}\;\ti{\<ithreetwo>}{a_7};\ti{\<ithreetwo>}{a_2};\phi_5
                \end{stackTL}}
            \end{stackTL}}
        }$$

    \item \refrule{Div-Prechk}

        Note that $\phi_5 = \phi_5,(\<ithreetwo>\; a_8),(= a_8 (\|\<div>\|\; a_1\; a_7))$.
        $$\infer{
            \phi_5 \implies \neg(= a_7\; 0) \\ a_8 \not\in \phi_5
        }{
            C_2\;
            {\begin{stackTL}
                \vdash (\<ithreetwo>.\<divpc>)
                \\ :
                {\begin{stackTL}
                    (\ti{\<ithreetwo>}{a_1}\;\ti{\<ithreetwo>}{a_7};\ti{\<ithreetwo>}{a_2};\phi_5
                    \\ \rightarrow \ti{\<ithreetwo>}{a_8};\ti{\<ithreetwo>}{a_2};\phi_6
                \end{stackTL}}
            \end{stackTL}}
        }$$

    \item \refrule{Composition}

        $$\infer{
            7. \\ 8.
        }{
            C_2\;
            {\begin{stackTL}
                \vdash (\<teelocal> 0)\; (\<ithreetwo>.\<const> 1)\; (\<getlocal> 0)\; (\<select>)\; (\<ithreetwo>.\<divpc>)
                \\ :
                {\begin{stackTL}
                    \ti{\<ithreetwo>}{a_1}\;\ti{\<ithreetwo>}{a_2};\ti{\<ithreetwo>}{a_3};\phi_1
                    \\ \rightarrow \ti{\<ithreetwo>}{a_8};\ti{\<ithreetwo>}{a_2};\phi_6
                \end{stackTL}}
            \end{stackTL}}
        }$$

    \item \refrule{Block}

    $$\infer{9.}{
        C_1 \vdash\;
        {\begin{stackTL}
            \<block>\;
            {\begin{stackTL}\ti{\<ithreetwo>}{a_1}\;\ti{\<ithreetwo>}{a_2};\ti{\<ithreetwo>}{a_3};\phi_1
                \\ \rightarrow \ti{\<ithreetwo>}{a_8};\ti{\<ithreetwo>}{a_2};\phi_6
            \end{stackTL}} \\
            \quad{\begin{stackTL}
                (\<teelocal> 0)
                \\ (\<ithreetwo>.\<const> 1)
                \\ (\<getlocal> 0)
                \\ (\<select>)
                \\ (\<ithreetwo>.\<div>)
            \end{stackTL}}
            \\ \<nsend> : \ti{\<ithreetwo>}{a_1}\;\ti{\<ithreetwo>}{a_2};\ti{\<ithreetwo>}{a_3};\phi_1
            \\ \rightarrow \ti{\<ithreetwo>}{a_8};\ti{\<ithreetwo>}{a_2};\phi_6
        \end{stackTL}}}$$
\end{enumerate}

\subsection{Module Types}
The complete module typing rules are in Figure \ref{fig:modulerules} (note that $im$ is an import and $ex$ is an export).
Functions $f$, typecheck their body $e^{*}$ under the module type context $C$ with the expected postcondition $ti_2^{*};l_2;\phi_2$ in the label stack and return position, and with the local index store $\ti{t_1}{a_1}^{*}\;\ti{t}{a_2}^{*}$ constructed from the function's arguments $\ti{t_1}{a_1}^{*}$ and declared locals $\ti{t}{a_2}^{*}$.
Global variables $glob$ must ensure that their initialization instructions $e^{*}$ produce a value of the proper type $t$.
Exported global variables cannot be mutable, if there are any exports defined, the global cannot have the mutable tag $mut$: $ex^{*}=\epsilon \lor tg=t$.
Tables $tab$ ensure that the indices $i^{n}$ refer to well-typed functions and there are exactly as many indices as the expected size $n$.
Memory $mem$ simply has its declared initial size $n$ from which it can only grow bigger.
All imported functions, globals, tables, and memories are expected to have their declared type.
They are typechecked during linking.

Typechecking a module involves typechecking every component of the module.
Functions, $f$, are typechecked under the module type context, $C$, containing the entirety of the module.
This means that functions can refer to themselves, other functions, all globals, the table, and memory.
This may seem to be a circular definition, but the type of the module is declared statically (as the combined declared types of all the module components), so it is just checking against the expected module index type context.
Globals, $glob$, are typechecked under the module index context containing only the global variable declarations preceding the current declaration.

\begin{figure}
    \begin{mathpar}
        \inferrule*[right=\defrule{Func}]{ %% local function
            \tfi = \ti{t_1}{a_1}^{*};\epsilon;\phi_1 \rightarrow ti_2^{*};l_2;\phi_2 \\
            C_2 = C,\text{local } t_1^{*}\;t^{*},\text{label } (ti_2^{*};l_2;\phi_2),\text{return } (ti_2^{*},l_2,\phi_2) \\
            C_2 \vdash e^{*} : \epsilon ;\ti{t_1}{a_1}^{*}\;\ti{t}{a_2}^{*};\phi_1 \rightarrow ti_2^{*};l_2;\phi_2
        } {
            C \vdash ex^{*}\; \<func> \tfi\; \<local> t^{*}\; e^{*} : ex^{*}\; \tfi
        } \and

        \inferrule*[]{ %% imported function
        } {
            C \vdash ex^{*}\; \<func> \tfi\; im : ex^{*}\; \tfi
        } \\

        \inferrule*[]{ %% local global
            tg = mut^{?}\;t \and
            ex^{*} = \epsilon \lor tg = t \and
            C \vdash e^{*} : \epsilon; \epsilon; \phi_1 \rightarrow \ti{t}{a};\epsilon; \phi_2
        } {
            C \vdash ex^{*}\; \<global> tg\; e^{*} : ex^{*}\; tg
        } \and

        \inferrule*[]{ %% imported global
            tg = t \and
        } {
            C \vdash ex^{*}\; \<global> tg\; im : ex^{*}\; tg
        } \and

        \inferrule*[right=\defrule{Table}]{ %% local table
            (C_{\text{func}}(i) = \tfi)^n
        } {
            C \vdash ex^{*}\; \<table> n\; i^n : ex^{*}\; (n,\tfi^n)
        } \and

        \inferrule*[]{ %% imported table
        } {
            C \vdash ex^{*}\; \<table> (n,\tfi^n)\; im : ex^{*}\; (n,\tfi^n)
        } \and

        \inferrule*[]{ %% local memory
        } {
            C \vdash ex^{*}\; \<memory> n : ex^{*}\; n
        }

        \inferrule*[]{ %% imported memory
        } {
            C \vdash ex^{*}\; \<memory> n\; im : ex^{*}\; n
        }

        \inferrule*[]{ %% module
            (C\vdash f : ex_f^{*}\; \tfi)^{*} \and
            (C_i \vdash glob_i : ex_g^{*}\; tg_i)^{*} \\
            (C \vdash tab : ex_t^{*}\; (n,\tfi^n))^{?} \and
            (C \vdash mem : ex_m^{*}\; n)^{?} \\
            (C_i=\{\text{global } tg^{i-1}\})_i^{*} \and
            ex_f^{*\;*}\; ex_g^{*\;*}\; ex_t^{*\;?}\; ex_m^{*\;?} \text{ distinct} \\
            C = \{\text{func } \tfi^{*}, \text{global } tg^{*}, \text{table } (n,\tfi^n)^{?}, \text{memory } n^{?}\}
        } {
            \vdash \<module> f^{*}\; glob^{*}\; tab^{?}\; mem^{?}
        }
    \end{mathpar}
    \caption{Indexed Module Typing Rules}
    \label{fig:modulerules}
\end{figure}
