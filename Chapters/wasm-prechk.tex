\chapter{\name}
\label{chp:prechk}
The goal of \name is to be used to eliminate unnecessary dynamic checks.
To accomplish this, it must (1) have instructions that do not require dynamic checks and (2) statically prove that the assumptions of those instructions are met.
In \name, we extend \wasm with new instructions that explicitly do not require dynamic checks, and design an indexed type system to reason about the safety of removing checks.

\section{\name Syntax}
The syntax of \name is highly similar to that of \wasm except for two additions.
First, \name introduces four additional instructions, which are referred to as ``\prechk-tagged'' instructions.
Second, \name changes the representation of types within \wasm instructions and functions.

Recall from \autoref{sec:wasmsemantics} that there are four \wasm instructions that require run-time checks: integer division, indirect function calls, and memory loads and stores.
``\prechk-tagged'' instructions refer to a set of four \name instructions, listed in \autoref{fig:newinstructions}, that are counterparts to these four \wasm instructions.
Intuitively, we are simply adding a tag to the instruction to show that it doesn't require run-time checks.
Formally, however, these are different instructions with different semantics and different typing rules, as explained below.

\begin{figure}[t]
    \begin{align*}
        &t.\<divpc> \mid
        t.\<callindirectpc> \mid
        \\
        &t.\<loadpc> (tp\_sx)^{?}\; a\;o \mid
        t.\<storepc> tp^{?\;} a\;o
    \end{align*}
    \caption{The four \prechk-tagged instructions}
    \label{fig:newinstructions}
\end{figure}

\subsection{The \name Index Language}
\label{subsec:indexlang}
\name uses an indexed type system.
An indexed type language uses an index language in the type system to encode information within types.
We use the index language to encode linear constraints on program variables within types.
\autoref{fig:itsyntax} shows the syntax for the index type language.
Remember, syntax written in a \tbbf{blue, bold font} denotes a \wasm keyword.
Below is a quick overview of each of the terms.

\begin{figure}[t]
    \begin{math}
        \begin{array}{rcl}
            t &:: & \<ithreetwo> \mid \<isixfour> \\
            a &::= & Index\; Variable \\
            x\;y &::=& a \mid \ti{t}{c} \mid (\<binop>\;x\;y) \mid (\<testop>\;x) \mid (\<relop>\;x\;y) \\
            P &::=& (=\; x \; y) \mid (\text{if}\; P\; P\; P) \mid \neg P \mid P \land P \mid P \lor P \\
            \phi &::=& \circ \mid \phi, \ti{t}{a} \mid \phi, P \\
        \end{array}
    \end{math}
    \caption{Syntax of the \name index type language}
    \label{fig:itsyntax}
\end{figure}

\begin{itemize}
    \item $t$ represents a primitive \wasm type.
    We do not reason about floating points, so it is either a 32-bit integer ($i32$) or a 64-bit integer ($i64$).
    \item $a$ is a type index variable, which is used to track constraints on program variables.
    \item $x$ and $y$ are type indices, they can be an index type variable, a constant with an explicit type, or a \wasm operation on a type index.
    \item $P$ is a proposition about type indices which can encode equality constraints on type indices, or combine propositions using common first-order logic operators.
    \item $\phi$ is the type index context which stores index type variable declarations and propositions.
    Essentially, it contains all of the knowledge we have about all of the index variables.
\end{itemize}

\begin{figure}[t]
    \begin{math}
        \begin{array}{rcl}
            ti &::=& \ti{t}{a} \\
            l &::=& ti^{*} \\
            tfi &::=& ti^{*};l;\phi \rightarrow ti^{*};l;\phi \\
            C &::=& \{
                {\begin{stackTL}
                    \text{func } \; tfi^{*}, \text{ global } \; (\text{mut}^{?} \; t)^{*}, \text{ table} \; n^{?}, \text{ memory }  m^{?}, \\
                    \text{ local } \; t^{*}, \text{ label}(ti^{*};l;\phi)^{*}, \text{ return}\;(ti^{*};l;\phi)^{? }\}
                \end{stackTL}}
        \end{array}
    \end{math}
    \caption{\name indexed function types}
    \label{fig:tfisyntax}
\end{figure}

Indexed types, $ti$, are used to associate index variables $a$ with values in the program.
\autoref{fig:tfisyntax} shows the form of an indexed type, which includes both the type $t$ and an index variable $a$.
In \name, we represent the shape of the stack as a sequence of indexed types $ti^{*}$.

The index local store associates index variables with local variables.
It has an identical form to the stack: a sequence of indexed types to associate index variables with local variables.
We use the shorthand $l$ to refer to the index local store since we rarely reason about it but rather thread it through typing rules.
The index type context $\phi$ is the mechanism that is used to reason about the possible values of computations.
It stores constraints on and between program variables tracked by indexed types representing the stack and index local store.

\name uses indexed function types $tfi$, which, similar to \wasm's function types, are just a precondition and postcondition.
However, indexed function types include much more information in their precondition and postcondition!
They represent the stack using a sequence of indexed types and track local variables using the index local store, and include $\phi$ which contains constraints about those values.

We retain $C$ to refer to the module type context in \name, although the representation of module types is slightly different.
\wasm function types are replaced with \name indexed function types.
Further, the postconditions in the label stack and return stack are replaced with \name indexed postconditions including indexed types, the local index store, and the index type context.

We can now introduce the \name typing judgement for instructions.
It is similar to the \wasm typing judgment, but uses indexed function types which include much more information by tracking constraints about program values.

\begin{mathpar}
    \boxed{C \vdash e^{*} : tfi}
\end{mathpar}

Recall that certain \wasm instructions (such as $\<block>$ and $\<callindirect>$) include \wasm function types to declare the expected types of their bodies.
In \name, we replace those function types with indexed function types.

\section{\name Dynamic Semantics}
\name uses the same reduction relation with the same structure as \wasm (explained in detail in \autoref{sec:wasmsemantics}).
All the reduction rules for all of the \name instructions are the same as they are for \wasm, except that indexed function types are used instead of \wasm function types.
We also have four new instructions, for which we introduce new reduction rules.

\label{sec:newinstructions}
\begin{figure}[t]
    \begin{mathpar}
        \boxed{s;v^{*};e^{*} \rightarrow s';v'^{*};e'^{*}}
    \end{mathpar}

    \begin{math}
        \arraycolsep=1.4pt
        \begin{array}{rcl}
            (t.\<const> c_1)\; (t.\<const> c_2)\; t.binop &\hookrightarrow& t.\<const> c \\
            \text{if } c=binop(c_1,c_2) && \\ %% binop

            (t.\<const> c_1)\; (t.\<const> c_2)\; t.binop &\hookrightarrow& \<trap> \\ %% binop to trap
            otherwise && \\

            s;\<callindirect> j &\hookrightarrow_i& s_\text{tab}(i,j) \\
            \text{if } s_\text{tab}(i,j)_\text{code}=(\<func> tf\; \<local>\; t^{*}\; e^{*}) && \\

            s;\<callindirect> j &\hookrightarrow_i& \<trap> \\
            \text{otherwise} && \\

            s;(\<ithreetwo>.\<const> k) &&\\
            (t.\<load> tp\_sx\; align\; o) &\hookrightarrow_i& s;(t.\<const> const_t(b^{*})) \\
            \text{if } s_\text{mem}(i,k+o,|t|)=b^{*} && \\

            &&\\

            s;(\<ithreetwo>.\<const> k) &&\\
            (t.\<load> tp\_sx\; align\; o) &\hookrightarrow_i& \<trap> \\
            \text{otherwise} && \\

            &&\\

            s;(\<ithreetwo>.\<const> k)\; (t.\<const> c) && \\
            (t.\<store> tp\_sx\; align\; o) &\hookrightarrow_i& s';\epsilon \\
            \text{if } s'=s &\text{ with }& \text{mem}(i,k+o,|t|)=bits_t(c) \\

            &&\\

            s;(\<ithreetwo>.\<const> k)\; (t.\<const> c) && \\
            (t.\<store> tp\_sx\; align\; o) &\hookrightarrow_i& \<trap> \\
            \text{otherwise} && \\
        \end{array}
    \end{math}
    \caption{\wasm instructions that have preconditions for reduction}
    \label{fig:checked}
\end{figure}

The formal reason certain \wasm instructions require run-time checks is because they have preconditions as part of their semantics, and if the preconditions are not met then those instructions trap to avoid undefined behavior (we've reproduced the reduction rules for those instructions in \autoref{fig:checked}).
The \wasm type system is not expressive enough to ensure these preconditions statically, so they instead must be checked at run-time.
Thus, ``\prechk-tagged'' instructions can assume that the preconditions on their behavior hold because it is enforced by the \name type system.
This can be seen in the reduction rules for the ``\prechk-tagged'' instructions in Figure \autoref{fig:prechkredux}, where they do not have rules to trap when their preconditions do not hold.

\label{sec:newinstructions}
\begin{figure}[t]
    \begin{mathpar}
        \boxed{s;v^{*};e^{*} \rightarrow s';v'^{*};e'^{*}}
    \end{mathpar}

    \begin{math}
        \arraycolsep=1.4pt
        \begin{array}{rcl}
            (t.\<const> c_1)\;(t.\<const> c_2) && \\
            t.\<divpc> & \hookrightarrow & c \\
            && \text{where } c_2 \neq 0 \land c=c_1/c_2 \\
            s;(t.\<const> j) && \\
            t.\<callindirectpc> & \hookrightarrow_i & \<call> s_{tab}(i,j) \\
            &&\text{where } s_{tab}(i,j) = \\
            && \<func> tfi\; \<local>\; t^{*}\;e^{*} \\
            s;(\<ithreetwo>.\<const> k) && \\
            (t.\<loadpc> (tp\_sx)^{?}\; a\;o) & \hookrightarrow_i & t.\<const> const_t(b^{*}) \\
            && \text{where } s_{mem}(i,k+o,|t|)=b^{*} \\
            s;(\<ithreetwo>.\<const> k)\;(t.\<const> c) && \\
            (t.\<storepc> tp^{?}\; a\;o) & \hookrightarrow_i & s';\epsilon \\
            && \text{where } s'=s \\
            && \text{with mem}(i,k+o,|t|)=bits_t^{|t|}(c) \\
        \end{array}
    \end{math}
    \caption{Behavior of new \prechk-tagged instructions}
    \label{fig:prechkredux}
\end{figure}

All other \name instructions have equivalent semantics to their \wasm versions as presented in \autoref{sec:wasmsemantics}.

\section{The \name Indexed Type System}
\label{sec:typesys}
The \name type system is designed to provide sufficient information to safely eliminate dynamic checks (\ie to ensure that the required preconditions are met to \prechk-tag an instruction).
As explained in ~\ref{subsec:indexlang}, the \name type system can encode linear constraints on program variables in the preconditions and postconditions of instructions.
We will now show how these constraints are added and used.

Recall the form of the \name typing judgement for instructions.
\begin{mathpar}
    \boxed{C \vdash e^{*} : ti_1^{*};l_1;\phi_1 \rightarrow ti_2^{*};l_2;\phi_2}
\end{mathpar}

Under $C$, the module type context, $e^{*}$ has the precondition $ti_1^{*};l_1;\phi_1$ and postcondition $ti_2^{*};l_2;\phi_2$.
We use the abbreviation $tfi ::= ti_1^{*};l_1;\phi_1 \rightarrow ti_2^{*};l_2;\phi_2$ as shorthand for the precondition and postcondition of an instruction.

As in \wasm, \name generally has two kinds of typing rules.
Most rules are for inferring or checking the types of instructions (in which case $e^{*}$ will be a single instruction).
There are also a few rules to compose together instruction sequences.
We present the typing rules mixed with discussion of those rules.
The typing judgment in its entirety is reproduced in the appendix.

Here are some of the simpler rules.
These are rules don't use or modify index type information.
\refrule{Unreachable} accepts any precondition and guarantees any postcondition since it just causes a trap.
In \refrule{Nop}, no changes are made from the precondition to the post condition because the instruction does nothing.
\refrule{Drop} consumes the top value from the stack (without caring about its type) and does not change the local index store or index type context.
\begin{mathpar}
    \inferrule*[right=\defrule{Unreachable}]{ }{ %% unreachable
        C \vdash \<unreachable> : tfi
    }

    \inferrule*[right=\defrule{Nop}]{ }{ %% nop
        C \vdash \<nop> : \epsilon;l;\phi \rightarrow \epsilon;l;\phi
    }

    \inferrule*[right=\defrule{Drop}]{ }{ %% drop
        C \vdash \<drop> : \ti{t}{a};l;\phi \rightarrow \epsilon;l;\phi
    }
\end{mathpar}

The constant instruction is a simple example of how indexed types work.
It adds a new indexed type onto the stack to track the new program variable $\ti{t}{a}$, declares the new indexed type in the index type context, and constrains that indexed type to be equal to the constant $(= a\; \ti{t}{c})$.
We require $a$ to be fresh, that is, we require that $a$ is a new index variable present no where else in any of the types for the program.
This is a common pattern to see in rules which introduce new index variables.
The local index store is unchanged between the precondition and postcondition.
\begin{mathpar}
    \inferrule*[right=\defrule{Const}]{ a \text{ is fresh} }{ %% const
        C \vdash t.\<const> c : \epsilon;l;\phi \rightarrow \ti{t}{a};l;\phi,\ti{t}{a},(= a \ti{t}{c})
    }
\end{mathpar}

There are several different kinds of operations, but they all work similarly.
The binary operator instruction adds constraints between new and old program values, since the result of the instruction is a new program values, while the consumed values may already be constrained.
A binary operation consumes two values from the stack, whiuch have associated indexed types $\ti{t}{a_1}$ and $\ti{t}{a_2}$, and produces a value which is associated with the fresh indexed type $\ti{t}{a_3}$.
The index type declaration $\ti{t}{a_3}$ is added to the index type context $\phi$ and $a_3$ is constrained to be equal to the binary operator applied to the index variables that correspond to the input $(= a_3\;(\|binop\|\;a_1\;a_2)$.
As a side note, we use $\|binop\|$ to indicate that we are using the $binop$ (or relop or testop) from the index language.
Binary operators do not affect or use local variables, they simply propagate, so the local index store. $l$, is the same in the precondition and postcondition.
\begin{mathpar}
    \inferrule*[right=\defrule{Binop}]{a_3 \text{ is fresh}}{ %% binop
        C \vdash t.binop : \ti{t}{a_1}\;\ti{t}{a_2};l;\phi \rightarrow \ti{t}{a_3};l;\phi,\ti{t}{a_3},(= a_3\;(\|binop\|\;a_1\;a_2))
    }

    \inferrule*[right=\defrule{Testop}]{a_2 \text{ is fresh}}{ %% testop
        C \vdash t.testop : \ti{t}{a_1}\;l;\phi \rightarrow \ti{\<ithreetwo>}{a_2};l;\phi,\ti{t}{a_2},(= a_2\;(\|testop\|\;a_1))
    }

    \inferrule*[right=\defrule{Relop}]{a_3 \text{ is fresh}}{ %% relop
        C \vdash t.relop : \ti{t}{a_1}\;\ti{t}{a_2};l;\phi \rightarrow \ti{t}{a_3};l;\phi,\ti{t}{a_3},(= a_3\;(\|relop\|\;a_1\;a_2))
    }
\end{mathpar}

\refrule{Select} constrains indexed types in a rather complex way.
Select consumes three values from the stack, it returns the second value if the third value is zero, and otherwise returns the first value (similar to C's ternary operator).
For this rule we use the type-level ``if'' to allow the constraint on the result to depend on the third value consumed: $(\text{if}\; (= a\; \ti{\<ithreetwo>}{0})\; (= a_3\;a_2)\; (= a_3\;a_1))$.
\begin{mathpar}
    \inferrule*[right=\defrule{Select}]{a_3 \text{ is fresh}}{ %% select
        C \vdash \<select> : {\begin{stackTL}
            \ti{t}{a_1}\;\ti{t}{a_2}\;\ti{i32}{a};l;\phi
            \\ \rightarrow \ti{t}{a_3};l;\phi,\ti{t}{a_3},
                (if\; (= a\; \ti{\<ithreetwo>}{0})\; (= a_3\;a_2)\; (= a_3\;a_1))
        \end{stackTL}}
    }
\end{mathpar}

The rules for the three different kinds of blocks (\<block>, \<loop>, and \<if>) are similar to \wasm.
They simply ensure that the interior instruction sequence has the expected type under the context with the expected postcondition (or precondition in the case of loop) appended to the local stack.
If blocks are able to make extra assumptions about the consumed value in the subsequences (that it is non-zero in the first sequence and zero in the second), because those constraints must be true for that sequence to be executed.
While \<if> and \<block> append their postcondition to the label stack for type checking branching instructions within the block, \<loop> appends its precondition because branching to a loop means running the loop again.

\begin{mathpar}
    \inferrule*[right=\defrule{Block}]{ %% block
        C_2,\text{label } (ti_2^{*};l_2;\phi_2) \vdash e^{*} : ti_1^{*};l_1;\phi_1 \rightarrow ti_2^{*};l_2;\phi_2 \\
    }
    {
        C \vdash \<block>\; (ti_1^{*};l_1;\phi_1 \rightarrow ti_2^{*};l_2;\phi_2)\; e^{*} \<end> : ti_1^{*};l_1;\phi_1 \rightarrow ti_2^{*};l_2;\phi_2
    }

    \inferrule*[right=\defrule{Loop}]{ %% loop
        C_2,\text{label } (ti_1^{*};l_1;\phi_1)^{*} \vdash e^{*} : ti_1^{*};l_1;\phi_1 \rightarrow ti_2^{*};l_2;\phi_2 \\
    }
    {
        C \vdash \<loop>\; (ti_1^{*};l_1;\phi_1 \rightarrow ti_2^{*};l_2;\phi_2)\; e^{*} \<end> : ti_1^{*};l_1;\phi_1 \rightarrow ti_2^{*};l_2;\phi_2
    }

    \inferrule*[right=\defrule{If}]{ %% if
        C_2,\text{label } (ti_2^{*};l_2;\phi_2) \vdash e_1^{*} : ti_1^{*};l_1;\phi_1, \neg(= a\; \ti{\<ithreetwo>}{0}) \rightarrow ti_2^{*};l_2;\phi_2 \\
        C_2,\text{label } (ti_2^{*};l_2;\phi_2) \vdash e_2^{*} : ti_1^{*};l_1;\phi_1, (= a\; \ti{\<ithreetwo>}{0})) \rightarrow ti_2^{*};l_2;\phi_2 \\
    }
    {
        C \vdash \<if>\; (ti_1^{*};l_1;\phi_1 \rightarrow ti_2^{*};l_2;\phi_2)\; e_1^{*} \<else> e_2^{*} \<end> : ti_1^{*};l_1;\phi_1 \rightarrow ti_2^{*};l_2;\phi_2
    }
\end{mathpar}

One thing to note is that all three of these rules include their expected preconditions and postconditions as part of their syntax.
We consider the index variables in these indexed function types to be unification variables rather then literals, allowing them to match any literal as long as the types unify.
Intuitively, this is very similar to alpha equivalence, where the precondition matches any preceding postcondition with the same structure as long as the variable can be renamed to match.
The postcondition appended to the label stack also has unification variables instead of the supplied literals.

The rules for branching instructions and return are similar to \wasm.
However, $\<brif>$ adds the assumption that the consumed value is zero to its postcondition.
This assumption can be safely added because the value must be zero for execution to continue without a branch occurring.
If the consumed value is constrained to be non-zero in the indexed type system, then this will cause a contradiction in the constraints of the index type context $\phi$.
However, that is fine since this means that no instructions following the $\<brif>$ will be executed.
Also remember the above note that the postconditions on the label stack contain unification variables, not literals.

Recall from \autoref{sec:wasmsemantics} that $\<brtable>$ branches to one of many different labels.
Thus, we must ensure that every possible branching postcondition it might branch to is implied by the precondition.

\begin{mathpar}
    \inferrule*[right=\defrule{Br}]{ %% br
        C_{\text{label}}(i) = ti^{*};l_1;\phi_1
    }
    {
        C \vdash \<br> i : ti_1^{*}\;ti^{*};l_1;\phi_1 \rightarrow ti_2^{*};l_2;\phi_2
    }

    \inferrule*[right=\defrule{Return}]{ %% return
        C_{\text{return}} = ti^{*};l_1;\phi_1
    }
    {
        C \vdash \<return> : ti_1^{*}\;ti^{*};l_1;\phi_1 \rightarrow ti_2^{*};l_2;\phi_2
    }

    \inferrule*[right=\defrule{Br-If}]{ %% br_if
        C_{\text{label}}(i) = ti^{*};l_1;\phi_1,\neg(= a\; \ti{\<ithreetwo>}{0})
    }
    {
        C \vdash \<brif> i : ti^{*}\;\index{i32}{a};l_1;\phi_1 \rightarrow ti^{*};l_1;\phi_1,(= a\; \ti{\<ithreetwo>}{0})
    }

    \inferrule*[right=\defrule{Br-Table}]{ %% br_table
        (C_{\text{label}}(i) = ti^{*};l_1;\phi_i)^{+} \and
        (\phi_1 \implies \phi_i)^n
    }
    {
        C \vdash \<brtable> i^{+} : ti_1^{*}\;ti^{*}\;\index{i32}{a};l_1;\phi_1 \rightarrow ti_2^{*};l_2;\phi_2
    }
\end{mathpar}

Recall that functions are declared within the module with a specific type $tfi$, that is a precondition and postcondition.
These declared indexed function types are placed inside the module type context $C$.
Direct function calls $\<call> i$ have the same type as the declared indexed function type of the function they are calling with two differences.
First, the local index store is unchanged, since the called function will have been turned into a closure that operates on separate local variables in a local block.
Second, the index type context in the postcondition is extended with the declarations and constraints from the precondition.
The precondition and postcondition of a function can only contain constraints about the arguments supplied to that function, so simply copying the postcondition of the function would result in the loss of information about all other index variables.

Indirect function calls $\<callindirect> ti_1^{*};l_1;\phi_1 \rightarrow ti_2^{*};l_2;\phi_2$ include the expected indexed function type $ti_1^{*};l_1;\phi_1 \rightarrow ti_2^{*};l_2;\phi_2$ provided as part of their syntax (the same note about index variables being unification variables from above holds).
Remember that indirect function calls perform a run time type check against the closure that they end up calling, so we assume statically that the check will proceed because if it does not the program will trap and not be able to do any harm.
The same two differences described above between the expected indexed function type $tfi$ and the type of the $\<callindirect> tfi$ instruction also hold.

\begin{mathpar}
    \inferrule*[right=\defrule{Call}]{ %% call
        C_\text{func}(i) = ti_1^{*};l_1;\phi_1 \rightarrow ti_2^{*};l_2;\phi_2
    }
    {
        C \vdash \<call> i : ti_1^{*};l;\phi_1 \rightarrow ti_2^{*};l;\phi_1,\phi_2
    } \and
    \inferrule*[right=\defrule{Call-Indirect}]{ %% call_indirect
        C_\text{table}(i) = (j, tfi_2^{*}) \and
    }
    {
        C \vdash \<callindirect> ti_1^{*};l_1;\phi_1 \rightarrow ti_2^{*};l_2;\phi_2 : ti_1^{*}\;\ti{i32}{a};l;\phi_1 \rightarrow ti_2^{*};l;\phi_1,\phi_2
    } \and
\end{mathpar}

The only instructions that actually mutate the local index store are those that operate on local variables.
$\<getlocal>$ produces a fresh indexed type $\ti{t}{a_2}$ that is constrained to be equal to the index variable associated with the local being retrieved.
$\<setlocal>$ works in the reverse direction, replacing the index variable associated with the local being set with a fresh indexed type constrained to be equal to the value consumed.
Finally, $\<teelocal>$ is effectively a $\<setlocal>$ that consumes and immediately regurgitates the indexed type back onto the stack, like the Unix tool ``tee''.
\begin{mathpar}
    \inferrule*[right=\defrule{Get-Local}]{ %% get_local
        C_{\text{local}}(i) = t \and
        l(i) = \ti{t}{a} \and
        a_2 \text{ is fresh}
    }
    {
        C \vdash \<getlocal> i : \epsilon;l;\phi \rightarrow \ti{t}{a_2};l;\phi, \ti{t}{a_2}, (= a_2\; a)
    }

    \inferrule*[right=\defrule{Set-Local}]{ %% set_local
        C_{\text{local}}(i) = t \and
        l_2 = l_1[i := \ti{t}{a_2}] \and
        a_2 \text{ is fresh}
    }
    {
        C \vdash \<setlocal> i : \ti{t}{a};l_1;\phi \rightarrow \epsilon;l_2;\phi, \ti{t}{a_2}, (= a_2\; a)
    }

    \inferrule*[right=\defrule{Tee-Local}]{ %% tee_local
        C_{\text{local}}(i) = t \and
        l_2 = l_1[i := \ti{t}{a_2}] \and
        a_2 \text{ is fresh}
    }
    {
        C \vdash \<teelocal> i : \ti{t}{a};l_1;\phi \rightarrow \ti{t}{a};l_2;\phi, \ti{t}{a_2}, (= a_2\; a)
    }
\end{mathpar}

Instructions for getting and setting globals produce and consume unconstrained values respectively.
Global variables are difficult to reason about in the type system since they are different between modules.
At compile-time, before linking, a module has no information about globals from another module which would be necessary for reasoning about the types of functions imported from the other module.
Therefore, we do not track index variables for globals.
We do still ensure that the value is of the correct type and in the case of setting a global variable that the global variable is mutable (has the ).
\begin{mathpar}
    \inferrule*[right=\defrule{Get-Global}]{ %% get_global
        C_\text{global}(i) = \text{mut}^{?}\; t \and
        a \text{ is fresh}
    }
    {
        C \vdash \<getglobal> i : \epsilon;l;\phi \rightarrow \ti{t}{a};l;\phi,\ti{t}{a}
    }

    \inferrule*[right=\defrule{Set-Global}]{ %% set_global
        C_\text{global}(i) = \text{mut } t
    }
    {
        C \vdash \<setglobal> i : \ti{t}{a};l;\phi \rightarrow \epsilon;l;\phi
    }
\end{mathpar}

The typing rules for memory instructions are very similar to \wasm as we do not reason about the contents of memory or how its size can change throughout a program.
As in \wasm, there are many small details related to how exactly values are loaded and store that are not particularly important to the understanding of the type system, but they are explained with the reduction rules for these values in \autoref{sec:wasmsemantics}.
One thing that does not appear in the \wasm reduction rules but mysteriously appears in the typing rules without much explanation is $align$.
According to the \wasm paper, $align$ is an ``alignment exponent''.
It is checked against the size of the type of the value being stored/loaded $|t|$ (or optionally $|tp|$, which should be less than $|t|$) in the premise $2^{align} \leq (|tp| <)^{?} |t|$.

\begin{mathpar}
    \inferrule*[right=\defrule{Mem-Load}]{ %% memory load
        C_\text{memory} = n \and
        2^{align} \leq (|tp| <)^{?} |t| \and
        a_2 \text{ is fresh}
    }
    {
        C \vdash t.\<load> (tp\_sx)^{?}\; align\; o : \ti{\<ithreetwo>}{a_1};l;\phi \rightarrow \ti{t}{a_2};l;\phi,\ti{t}{a_2}
    }

    \inferrule*[right=\defrule{Mem-Store}]{ %% memory store
        C_\text{memory} = n \and
        2^{align} \leq (|tp| <)^{?} |t|
    }
    {
        C \vdash t.\<store> tp^{?}\; align\; o : \ti{\<ithreetwo>}{a_1}\;\ti{t}{a_2};l;\phi \rightarrow \epsilon;l;\phi
    }

    \inferrule*[right=\defrule{Current-Memory}]{ %% current mem
        C_\text{memory} = n \and
        a \text{ is fresh}
    }
    {
        C \vdash \<currentmemory> : \epsilon;l;\phi \rightarrow \ti{\<ithreetwo>}{a};l;\phi
    }

    \inferrule*[right=\defrule{Grow-Memory}]{ %% grow mem
        C_\text{memory} = n \and
        a_2 \text{ is fresh}
    }
    {
        C \vdash \<growmemory> : \ti{\<ithreetwo>}{a_1};l;\phi \rightarrow \ti{\<ithreetwo>}{a_2};l;\phi
    }
\end{mathpar}

The last rules are the ones that can be used to compose sequences of instructions.
The first rule is for the empty instruction sequence $\epsilon$, which, similar to in \wasm, simply has the same precondition and postcondition $\epsilon;l;\phi$.
Second, we have \refrule{Stack-Poly} to add stack polymorphism (see \autoref{subsec:stackpoly}).
Third, there is a rule to compose a sequence of instructions $e_1^{*}$ with another instruction $e_2$.
\begin{mathpar}
    \inferrule*[right=\defrule{Empty}]{ %% empty
    }
    {
        C \vdash \epsilon : \epsilon;l;\phi \rightarrow \epsilon;l;\phi
    }

    \inferrule*[right=\defrule{Stack-Poly}]{ %% extra vars
        C \vdash e^{*} : ti_1^{*};l_1;\phi_1 \rightarrow ti_2^{*};l_2;\phi_2
    }
    {
        C \vdash e^{*} : ti^{*}\;ti_1^{*};l_1;\phi_1 \rightarrow ti^{*}\;ti_2^{*};l_2;\phi_2
    }

    \inferrule*[right=\defrule{Composition}]{ %% combine
        C \vdash e_1^{*} : ti_1^{*};l_1;\phi_1 \rightarrow ti_2^{*};l_2;\phi_2 \\
        C \vdash e_2 : ti_2^{*};l_2;\phi_2 \rightarrow ti_3^{*};l_3;\phi_3
    }
    {
        C \vdash e_1^{*}\;e_2 : ti_1^{*};l_1;\phi_1 \rightarrow ti_3^{*};l_3;\phi_3
    }
\end{mathpar}

\subsection{Subtyping, Implication, and Constraint Satisfaction}
\label{subsec:subtyping}
One issue with adding the index type context $\phi$ to preconditions and postconditions is that the postcondition of one instruction and the precondition of the next instruction might not match up exactly.
For example, one instruction may ensure a value is greater than ten, but the next just wants the value to be greater than zero.
Intuitively, if a value, ``x'', is greater than ten it must also be greater than zero, and we want the \name type system to be able to figure this out as well.
However, computers as of yet are unable to use intuition, so we must instead formalize this.

Our formalization of this problem is to allow \emph{strengthening} preconditions and \emph{weakening} postconditions.
Strengthening and weakening is based on implication ($\implies$).
We say that $\phi_1 \implies \phi_2$ when the following holds: if $\phi_1$ is satisfied, then $\phi_2$ must also be satisfied.
If $\phi_1 \implies \phi_2$, then we consider $\phi_1$ to be stronger than $\phi_2$, and $\phi_2$ to be weaker than $\phi_1$.
This solves the aforementioned problem because we can weaken ``x is greater than 10'' to ``x is greater than 0'' (or equivalently strengthen ``x is greater than 0'' to ``x is greater than 10'').

To fit strengthening and weakening into the type system, we define a subtyping judgment based on implication.
The \refrule{Implies} says that if an indexed function type $tfi_1$ has a stronger precondition and weaker postcondition than some other indexed function type $tfi_2$, and is otherwise equivalent, then $tfi_1$ is a subtype of $tfi_2$.

\begin{mathpar}
    \inferrule*[right=\defrule{Implies}]{
        \satisfies{\phi_0}{ti_1^{*}\;l_1}{\phi_1} \and
        \satisfies{\phi_2}{ti_2^{*}\;l_2}{\phi_3}
    }{
        ti_1^{*};l_1;\phi_0 \rightarrow ti_2^{*};l_2;\phi_3 <: ti_1^{*};l_1;\phi_1 \rightarrow ti_2^{*};l_2;\phi_2
    }
\end{mathpar}

We then use this in the \name type system by adding a typing rule that allows the indexed function type for a list of instructions to be replaced by a subtype of that indexed function type.

\[
    \inferrule*[right=\defrule{SubTyping}]{
        ti_1^{*};l_1;\phi_0 \rightarrow ti_2^{*};l_2;\phi_3 <: ti_1^{*};l_1;\phi_1 \rightarrow ti_2^{*};l_2;\phi_2 \\
        C \vdash e^{*} \rightarrow ti_1^{*};l_1;\phi_1 \rightarrow ti_2^{*};l_2;\phi_2
    }{
        C \vdash e^{*} \rightarrow ti_1^{*};l_1;\phi_0 \rightarrow ti_2^{*};l_2;\phi_3
    }
\]

\subsection{Using Types for Check Elimination}
In Section \ref{sec:newinstructions} we explained why \prechk-tagged instructions do not need dynamic checks because of their static guarantees of the \name type system.
Now, we will see how the \name type system provides those guarantees by looking at the typing rules for each of the \prechk-tagged instructions.

Integer division simply requires that the second argument is non-zero.
The premise $\phi \implies \neg(=\ a_2\ 0)$ requires that the index constraints satisfy the proposition $a_2 \neq 0$ for the pre-checked instruction to be safe.
Therefore, since a divide-by-zero is provably absent, it is safe to use the \prechk-tagged division instruction.
As an aside, recall that $a_3 \not\in \phi$ ensures that $a_3$ is fresh.
\begin{mathpar}
    \inferrule*[right=\defrule{Div-Prechk}]{
        \phi \implies \neg(=\ a_2\ 0) \and
        a_3 \not\in \phi
    }{
        C \vdash t.\<divpc> : \ti{t}{a_1}\;\ti{t}{a_2};l;\phi \rightarrow \ti{t}{a_3};l;\phi,\ti{t}{a_3},(= a_3\;(div\;a_1\;a_2))
    }
\end{mathpar}

Tagging memory loads and stores with \prechk requires ensuring that the memory index is valid.
Since \wasm and \name use linear memory which is a contiguous block of memory, we simply have to ensure that the index is within those bounds.
The initial memory size is the number of $64$ Ki pages ($65,536$ bytes), so we check that the constraints in the index type context ensure that the memory index plus the static offset is between $0$ and $65536-(the size of the value being loaded/stored)$.
We use $width$ as a shorthand to denote the number of bytes requires for the value, it is equal to $|t|/8$ if $tp^{?}=\epsilon$, and otherwise equal to $|tp|/8$.

Unfortunately, while the size of memory may be grown during program execution, we are currently unable to reason about changing memory size.
Therefore, we just use the initial memory size.
\begin{mathpar}
    \inferrule*[right=\defrule{Load-Prechk}]{ %% memory load
        C_\text{memory} = n \and
        2^{align} \leq (|tp| <)^{?} |t| \and
        a_3 \not\in \phi \\
        \phi \implies
        {\begin{stackTL}
            (\<ge> (\<add> a_1\; \ti{\<ithreetwo>}{o}) \ti{\<ithreetwo>}{0}), 
            \\ (\<le> (\<add> a_1\; (\<add> \ti{\<ithreetwo>}{o+width}))\; \ti{\<ithreetwo>}{n*64 \text{Ki}})
        \end{stackTL}}
    }
    {
        C \vdash t.\<loadpc> (tp\_sx)^{?}\; align\; o : \ti{\<ithreetwo>}{a_1};l;\phi \rightarrow \ti{t}{a_2};l;\phi,\ti{t}{a_2}
    }

    \inferrule*[right=\defrule{Store-Prechk}]{ %% memory store
        C_\text{memory} = n \and
        2^{align} \leq (|tp| <)^{?} |t| \\
        \phi \implies
        {\begin{stackTL}
            (\<ge> (\<add> a_1\; \ti{\<ithreetwo>}{o}) \ti{\<ithreetwo>}{0}), 
            \\ (\<le> (\<add> a_1\; (\<add> \ti{\<ithreetwo>}{o+width}) \ti{\<ithreetwo>}{0}) \ti{\<ithreetwo>}{n*64\text{Ki}})
        \end{stackTL}}
    }
    {
        C \vdash t.\<storepc> tp^{?}\; align\; o : \ti{\<ithreetwo>}{a_1}\;\ti{t}{a_2};l;\phi \rightarrow \epsilon;l;\phi
    }
\end{mathpar}

Indirect function calls in \wasm require a dynamic check to ensure that the index into the table points to a function of a suitable type (recall the explanation of tables and \<callindirect> from \autoref{sec:wasmsemantics}).
Proving the safety of an indirect function call involves showing that every possible function that could be called will not cause a run-time type error.
We ensure this by requiring that the type of every function at every possible index value has a subtype of the expected type: $\forall 0 \leq i < j. (\phi \implies \neg (= \ti{\<ithreetwo>}{i}\; a)) \lor tfis(i) <: tfi$ where $tfis=(tfi_2 ...)$.
Further, we must show that the provided table index is within the table boundaries: $\phi \implies 0 \leq c < j$.
\begin{mathpar}
    \inferrule*[right=\defrule{Call-Indirect-Prechk}]{ %% call_indirect
        C_{table}(i) = (j, (tfi_2 ...)) \and
        \phi \implies 0 \leq c < j \\
        tfi = ti_1^{*};l_1;\phi_1 \rightarrow ti_2^{*};l_2;\phi_2 \\
        \forall 0 \leq i < j.\;
        {\begin{stackTL}
            (\phi \implies \neg (= \ti{\<ithreetwo>}{i}\; a)) 
            \\ \lor\; tfis(i) <: tfi$ where $tfis=(tfi_2 ...)
        \end{stackTL}}
    }
    {
        C \vdash \<callindirectpc> tfi : ti_1^{*}\;\ti{i32}{a};l;\phi_1 \rightarrow ti_2^{*};l;\phi_1,\phi_2
    } \and
\end{mathpar}

\subsection{Module Types}
The complete module typing rules are in Figure \ref{fig:modulerules} (not that $im$ is an import and $ex$ is an export).
Functions $f$, typecheck their body $e^{*}$ under the module type context $C$ with the expected postcondition $ti_2^{*};l_2;\phi_2$ in the label stack and return position, and with the local index store $\ti{t_1}{a_1}^{*}\;\ti{t}{a_2}^{*}$ constructed from the function's arguments $\ti{t_1}{a_1}^{*}$ and declared locals $\ti{t}{a_2}^{*}$.
Global variables $glob$ must ensure that their initialization instructions $e^{*}$ produce a value of the proper type $t$.
Exported global variables cannot be mutable, if there are any exports defined, the global cannot have the mutable tag $mut$: $ex^{*}=\epsilon \lor tg=t$.
Tables $tab$ ensure that the indices $i^{n}$ refer to well-typed functions and there are exactly as many indices as the expected size $n$.
Memory $mem$ simply has its declared initial size $n$ from which it can only grow bigger.
All imported functions, globals, tables, and memories are expected to have their declared type.
They are type checked during linking.

Type checking a module involves typechecking every component of the module.
Functions, $f$, are typechecked under the module type context, $C$, containing the entirety of the module.
This means that functions can refer to themselves, other functions, all globals, the table, and memory.
This may seem to be a circular definition, but the type of the module is declared statically (as the combined declared types of all the module components), so it is just checking against the expected module index type context.
Globals, $glob$, are typechecked under the module index context containing only the global variable declarations preceding the current declaration.

\begin{figure}[h]
    \begin{mathpar}
        \inferrule*[]{ %% local function
            tfi = \ti{t_1}{a_1}^{*};\epsilon;\phi_1 \rightarrow ti_2^{*};l_2;\phi_2 \\
            C_2 = C,\text{local } t_1^{*}\;t^{*},\text{label } (ti_2^{*};l_2;\phi_2),\text{return } (ti_2^{*},l_2,\phi_2) \\
            C_2 \vdash e^{*} : \epsilon ;\ti{t_1}{a_1}^{*}\;\ti{t}{a_2}^{*};\phi_1 \rightarrow ti_2^{*};l_2;\phi_2
        } {
            C \vdash ex^{*}\; \<func> tfi\; \<local> t^{*}\; e^{*} : ex^{*}\; tfi
        } \and

        \inferrule*[]{ %% imported function
        } {
            C \vdash ex^{*}\; \<func> tfi\; im : ex^{*}\; tfi
        } \\

        \inferrule*[]{ %% local global
            tg = mut^{?}\;t \and
            ex^{*} = \epsilon \lor tg = t \and
            C \vdash e^{*} : \epsilon; \epsilon; \phi_1 \rightarrow \ti{t}{a};\epsilon; \phi_2
        } {
            C \vdash ex^{*}\; \<global> tg\; e^{*} : ex^{*}\; tg
        } \and

        \inferrule*[]{ %% imported global
            tg = t \and
        } {
            C \vdash ex^{*}\; \<global> tg\; im : ex^{*}\; tg
        } \and

        \inferrule*[]{ %% local table
            (C_{\text{func}}(i) = tfi)^n
        } {
            C \vdash ex^{*}\; \<table> n\; i^n : ex^{*}\; (n,tfi^n)
        } \and

        \inferrule*[]{ %% imported table
        } {
            C \vdash ex^{*}\; \<table> (n,tfi^n)\; im : ex^{*}\; (n,tfi^n)
        } \and

        \inferrule*[]{ %% local memory
        } {
            C \vdash ex^{*}\; \<memory> n : ex^{*}\; n
        }

        \inferrule*[]{ %% imported memory
        } {
            C \vdash ex^{*}\; \<memory> n\; im : ex^{*}\; n
        }

        \inferrule*[]{ %% module
            (C\vdash f : ex_f^{*}\; tfi)^{*} \and
            (C_i \vdash glob_i : ex_g^{*}\; tg_i)^{*} \\
            (C \vdash tab : ex_t^{*}\; (n,tfi^n))^{?} \and
            (C \vdash mem : ex_m^{*}\; n)^{?} \\
            (C_i=\{\text{global } tg^{i-1}\})_i^{*} \and
            ex_f^{*\;*}\; ex_g^{*\;*}\; ex_t^{*\;?}\; ex_m^{*\;?} \text{ distinct} \\
            C = \{\text{func } tfi^{*}, \text{global } tg^{*}, \text{table } (n,tfi^n)^{?}, \text{memory } n^{?}\}  
        } {
            \vdash \<module> f^{*}\; glob^{*}\; tab^{?}\; mem^{?}
        }
    \end{mathpar}
    \caption{Indexed Module Typing Rules}
    \label{fig:modulerules}
\end{figure}